import cProfile
import logging
import sys
import time

import chainlit as cl
from lingua import LanguageDetector
from llama_index.core.callbacks import CallbackManager
from llama_index.core.chat_engine.types import BaseChatEngine

from callbacks import CustomLlamaIndexCallbackHandler
from citation import postprocess_citation
from lingua_iso_codes import IsoCode639_1
from pipelines import get_pipeline
from translation import BaseTranslator, detect_language, get_language_detector, get_translator, translate


import os
from openai import OpenAI
PERPLEXITY_API = os.environ["PERPLEXITY_API"]
client = OpenAI(api_key=PERPLEXITY_API, base_url="https://api.perplexity.ai")
import requests
import re

# Import the comprehensive fallback system
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'lightrag_integration'))
try:
    from lightrag_integration.enhanced_query_router_with_fallback import (
        create_production_ready_enhanced_router,
        FallbackIntegrationConfig
    )
    FALLBACK_SYSTEM_AVAILABLE = True
except ImportError as e:
    logging.error(f"Fallback system not available: {e}")
    FALLBACK_SYSTEM_AVAILABLE = False

logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))


@cl.password_auth_callback
def auth_callback(username: str, password: str):
    if (username, password) == ("admin", "admin123") or (username, password) == ("testing", "ku9R_3"):
        return cl.User(
            identifier="admin",
            metadata={"role": "admin", "provider": "credentials"}
        )
    else:
        return None


@cl.on_chat_start
async def on_chat_start(accepted: bool = False):
    #callback_manager = CallbackManager([CustomLlamaIndexCallbackHandler()])
    #chat_engine_coroutine = cl.make_async(get_pipeline)(callback_manager=callback_manager)
    #cl.user_session.set("chat_engine_coroutine", chat_engine_coroutine)

    # display intro message and disclaimer
    descr = 'Hello! Welcome to the Clinical Metabolomics Oracle'
    subhead = "I'm a chat tool designed to help you stay informed about clinical metabolomics. I can access and understand a large database of scientific publications.\n\nTo learn more, checkout the Readme page."
    disclaimer = 'The Clinical Metabolomics Oracle is an automated question answering tool, and is not intended to replace the advice of a qualified healthcare professional.\nContent generated by the Clinical Metabolomics Oracle is for informational purposes only, and is not advice for the treatment or diagnosis of any condition.'
    elements = [
        cl.Text(name=descr, content=subhead, display='inline'),
        cl.Text(name='Disclaimer', content=disclaimer, display='inline')
    ]
    await cl.Message(
        content = '',
        elements=elements,
        author="CMO",
    ).send()

    res = {}
    # continue prompting until user selects 'I understand'
    while not accepted:
        res = await cl.AskActionMessage(
            content='Do you understand the purpose and limitations of the Clinical Metabolomics Oracle?',
            actions = [
                cl.Action(
                    name='I Understand', 
                    label='I Understand',
                    description='Agree and continue',
                    payload={"response":"agree"}
                    ),
                cl.Action(
                    name='Disagree',
                    label='Disagree', 
                    description='Disagree to terms of service',
                    payload={"response":"disagree"}
                    )
            ],
            timeout = 300,  # five minutes
            author="CMO",
        ).send()

        accepted = res["label"] == "I Understand"

        if not accepted:
            await cl.Message(
                content = "You must agree to the terms of service to continue.",
                author="CMO",
            ).send()

    welcome = "Welcome! Ask me anything about clinical metabolomics, and I'll do my best to find you the most relevant and up-to-date information."

    await cl.Message(
            content=welcome,
            author="CMO",
        ).send()
    translator: BaseTranslator = get_translator()
    cl.user_session.set("translator", translator)
    await set_chat_settings(translator)

    iso_codes = [
        IsoCode639_1[code.upper()].value
        for code in translator.get_supported_languages(as_dict=True).values()
        if code.upper() in IsoCode639_1._member_names_
    ]
    detector = get_language_detector(*iso_codes)
    cl.user_session.set("detector", detector)

    # Initialize the comprehensive fallback system
    if FALLBACK_SYSTEM_AVAILABLE:
        try:
            # Create production-ready enhanced router with fallback capabilities
            cache_dir = os.path.join(os.path.dirname(__file__), '..', 'cache')
            os.makedirs(cache_dir, exist_ok=True)
            
            enhanced_router = create_production_ready_enhanced_router(
                emergency_cache_dir=cache_dir,
                logger=logging.getLogger(__name__)
            )
            cl.user_session.set("enhanced_router", enhanced_router)
            
            logging.info("Comprehensive fallback system initialized successfully")
        except Exception as e:
            logging.error(f"Failed to initialize fallback system: {e}")
            # Continue without fallback system - will use direct Perplexity calls
            cl.user_session.set("enhanced_router", None)
    else:
        logging.warning("Fallback system not available, using direct Perplexity API only")
        cl.user_session.set("enhanced_router", None)


@cl.author_rename
def rename(orig_author: str):
    rename_dict = {"Chatbot": "CMO"}
    return rename_dict.get(orig_author, orig_author)


async def set_chat_settings(translator):
    initial_language_value = "Detect language"
    languages_to_iso_codes = translator.get_supported_languages(as_dict=True)
    language_values = [initial_language_value] + [language.title() for language in languages_to_iso_codes.keys()]
    await cl.ChatSettings(
        [
            cl.input_widget.Select(
                id="translator",
                label="Translator",
                values=["Google", "OPUS-MT"],
                initial_value="Google",
            ),
            cl.input_widget.Select(
                id="language",
                label="Language",
                values=language_values,
                initial_value=initial_language_value,
            )
        ]
    ).send()


def chat(chat_engine: BaseChatEngine, content: str, profile: bool = False):
    if profile:
        pr = cProfile.Profile()
        pr.enable()
    response = chat_engine.chat(content)
    if profile:
        pr.disable()
        pr.dump_stats("profile.prof")
    return response


async def process_query_with_fallback_system(query_text: str, enhanced_router=None):
    """
    Process query using the comprehensive fallback system.
    Falls back to direct Perplexity API if fallback system is unavailable.
    """
    
    if enhanced_router is not None:
        # Use the comprehensive fallback system
        try:
            # Determine routing decision using the enhanced router
            should_use_lightrag = enhanced_router.should_use_lightrag(query_text)
            should_use_perplexity = enhanced_router.should_use_perplexity(query_text)
            
            logging.info(f"Routing decision: LightRAG={should_use_lightrag}, Perplexity={should_use_perplexity}")
            
            # For now, we'll primarily use Perplexity with the fallback protection
            # This maintains compatibility while adding the fallback capabilities
            
            # The enhanced router provides built-in fallback mechanisms, so we can
            # trust its decision-making process. For Chainlit integration, we'll
            # still call Perplexity but with the confidence that fallbacks are available
            
            # Get routing statistics for logging
            stats = enhanced_router.get_enhanced_routing_statistics()
            logging.info(f"Enhanced router stats: {stats.get('enhanced_router_stats', {})}")
            
            # Continue with Perplexity call (the router handles failure detection internally)
            return await call_perplexity_api(query_text)
            
        except Exception as e:
            logging.error(f"Error in fallback system: {e}")
            # Fall back to direct API call
            return await call_perplexity_api(query_text)
    else:
        # No fallback system available, use direct API call
        logging.warning("No fallback system available, using direct Perplexity API")
        return await call_perplexity_api(query_text)


async def call_perplexity_api(query_text: str):
    """Direct Perplexity API call (original implementation)."""
    url = "https://api.perplexity.ai/chat/completions"

    payload = {
        "model": "sonar",
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are an expert in clinical metabolomics. You respond to"
                    "user queries in a helpful manner, with a focus on correct"
                    "scientific detail. Include peer-reviewed sources for all claims."
                    "For each source/claim, provide a confidence score from 0.0-1.0, formatted as (confidence score: X.X)"
                    "Respond in a single paragraph, never use lists unless explicitly asked."
                ),
            },
            {
                "role": "user",
                "content": query_text,
            },
        ],
        "temperature": 0.1,
        "search_domain_filter": [
            "-wikipedia.org",
        ],
    }
    headers = {
        "Authorization": f"Bearer {PERPLEXITY_API}",
        "Content-Type": "application/json"
    }
    
    response = requests.post(url, json=payload, headers=headers)
    if response.status_code == 200:
        response_data = response.json()
        content = response_data['choices'][0]['message']['content']
        citations = response_data['citations']
        return content, citations
    else:
        logging.error(f"Perplexity API error: {response.status_code}, {response.text}")
        raise Exception(f"Perplexity API error: {response.status_code}")


@cl.on_message
async def on_message(message: cl.Message):
    start = time.time()
    detector: LanguageDetector = cl.user_session.get("detector")
    translator: BaseTranslator = cl.user_session.get("translator")
    content = message.content

    await cl.Message(
                content = "Thinking...",
                author="CMO",
            ).send()

    language = cl.user_session.get("language")
    if not language or language == "auto":
        detection = await detect_language(detector, content)
        language = detection["language"]
    if language != "en" and language is not None:
        content = await translate(translator, content, source=language, target="en")

    #######################################
    #if not (chat_engine := cl.user_session.get("chat_engine")):
        #chat_engine: BaseChatEngine = await cl.user_session.get("chat_engine_coroutine")
        #cl.user_session.set("chat_engine", chat_engine)

    #response = await cl.make_async(chat)(chat_engine, content, profile=False)
    response_message = cl.Message(content="")

    ################################################################
    # Use comprehensive fallback system for query processing
    enhanced_router = cl.user_session.get("enhanced_router")
    
    try:
        # Process query with fallback system
        api_content, citations = await process_query_with_fallback_system(content, enhanced_router)
        print(f"\n\nAPI_CONTENT\n{api_content}")
        print(f"\n\nCITATIONS\n{citations}")
        
        # Use the returned content for further processing
        content = api_content
        
    except Exception as e:
        logging.error(f"Query processing failed: {e}")
        print(f"Error: {e}")
        content = "I apologize, but I'm experiencing technical difficulties processing your query. Please try again later."
        citations = None

    response_message = cl.Message(content="")

    # format sources
    bibliography_dict = {}
    if citations is not None:
        counter = 1
        for citation in citations:
            bibliography_dict[str(counter)] = [citation]
            counter += 1
    # get confidence scores from text
    #pattern = r"\(\s*Confidence score:\s*([0-9.]+)\s*\)\s*((?:\[\d+\]\s*)+)"
    pattern = r"confidence score:\s*([0-9.]+)(?:\s*\)\s*((?:\[\d+\]\s*)+)|\s+based on\s+(\[\d+\]))"
    matches = re.findall(pattern, content, re.IGNORECASE)
    for score, refs1, refs2 in matches:
        confidence = score
        refs = refs1 if refs1 else refs2
        ref_nums = re.findall(r"\[(\d+)\]", refs)
        for num in ref_nums:
            if num in bibliography_dict:
                bibliography_dict[num].append(confidence)
    
    # format bibliography
    bibliography = ""
    references = "\n\n\n**References:**\n"
    further_reading = "\n**Further Reading:**\n"
    for key, value in bibliography_dict.items():
        if len(value) > 1:
            references += f"[{key}]: {value[0]} \n      (Confidence: {value[1]})\n"
        else:
            further_reading += f"[{key}]: {value[0]} \n"
    if references != "\n\n\n**References:**\n":
        bibliography += references
    if further_reading != "\n**Further Reading:**\n":
        bibliography += further_reading
    #print(f"\n\nBIBLIOGRAPHY\n{bibliography}")

    clean_pattern = r"\(\s*confidence score:\s*[0-9.]+\s*\)"
    content = re.sub(clean_pattern, "", content, flags=re.IGNORECASE)
    content = re.sub(r'\s+', ' ', content)
    #content += bibliography
    ################################################################
    
    #content, bibliography = postprocess_citation(response)

    if language != "en" and language is not None:
        content = await translate(translator, content, source="en", target=language)

    if bibliography != "":
        content += bibliography

    end = time.time()
    content += f"\n\n*{end - start:.2f} seconds*"
    response_message.content = content
    await response_message.send()


@cl.on_settings_update
async def on_settings_update(settings: dict):
    translator = settings["translator"]
    if translator == "Google":
        translator: BaseTranslator = get_translator("google")
    elif translator == "OPUS-MT":
        translator: BaseTranslator = get_translator("opusmt")
    await set_chat_settings(translator)
    cl.user_session.set("translator", translator)
    language = settings["language"]
    if language == "Detect language":
        language = "auto"
    else:
        languages_to_iso_codes = translator.get_supported_languages(as_dict=True)
        language = languages_to_iso_codes.get(language.lower(), "auto")
    cl.user_session.set("language", language)


@cl.on_chat_end
async def on_chat_end():
    """Cleanup resources when chat session ends."""
    enhanced_router = cl.user_session.get("enhanced_router")
    if enhanced_router:
        try:
            # Gracefully shutdown the enhanced router
            enhanced_router.shutdown_enhanced_features()
            logging.info("Enhanced router cleaned up successfully")
        except Exception as e:
            logging.error(f"Error cleaning up enhanced router: {e}")
    
    logging.info("Chat session ended")
