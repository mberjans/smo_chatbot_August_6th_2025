[tool:pytest]
# Pytest configuration for routing decision analytics tests

# Test paths
testpaths = tests

# Python files to collect tests from
python_files = test_*.py *_test.py test_routing_*.py

# Python functions to collect as tests
python_functions = test_*

# Python classes to collect tests from
python_classes = Test*

# Minimum Python version
minversion = 3.8

# Test discovery patterns
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --showlocals
    --durations=10
    --asyncio-mode=auto

# Markers for test categorization
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    performance: marks tests as performance tests  
    async_test: marks tests that require async support
    unit: marks tests as unit tests
    requires_temp_files: marks tests that require temporary file creation
    requires_network: marks tests that require network access
    parametrize: marks parametrized tests

# Asyncio configuration
asyncio_mode = auto

# Test timeout (in seconds)
timeout = 300

# Logging configuration
log_level = INFO
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)d)
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/test_routing_analytics.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)d)
log_file_date_format = %Y-%m-%d %H:%M:%S

# Coverage configuration (if using pytest-cov)
# addopts = --cov=lightrag_integration --cov-report=html --cov-report=term-missing --cov-fail-under=85

# Test discovery
norecursedirs = 
    .git
    .tox
    dist
    build
    *.egg
    __pycache__
    .pytest_cache
    venv
    env
    lightrag_env
    lightrag_test_env

# Filter warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:lightrag.*
    ignore::RuntimeWarning:asyncio.*

# Test execution
# Run tests in parallel (if pytest-xdist is available)
# addopts = -n auto

# Fail fast - stop on first failure
# addopts = -x

# Drop into debugger on failures
# addopts = --pdb

# Show extra test summary info
# addopts = -r fEsxX

# Control test verbosity levels:
# -v: verbose
# -vv: more verbose  
# -q: quiet
# --tb=short: shorter traceback format
# --tb=line: one line per failure
# --tb=no: no traceback

[coverage:run]
# Coverage configuration (if using coverage.py)
source = lightrag_integration
omit = 
    */tests/*
    */test_*.py
    */__pycache__/*
    */venv/*
    */env/*
    */lightrag_env/*
    */lightrag_test_env/*

[coverage:report]
# Coverage reporting
precision = 2
show_missing = true
skip_covered = false
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstract