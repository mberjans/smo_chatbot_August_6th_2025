[tool:pytest]
# Pytest Configuration for Multi-Level Fallback Scenario Testing
# ==============================================================

# Test discovery
testpaths = tests
python_files = test_multi_level_fallback_scenarios.py test_fallback_*.py
python_classes = Test*Fallback* Test*MultiLevel*
python_functions = test_*fallback* test_*multi_level*

# Output and reporting
addopts = 
    --verbose
    --tb=short
    --durations=20
    --strict-markers
    --strict-config
    --color=yes
    --junit-xml=reports/fallback_tests_junit.xml
    --html=reports/fallback_tests_report.html
    --self-contained-html
    --cov=lightrag_integration
    --cov-report=html:reports/fallback_coverage_html
    --cov-report=xml:reports/fallback_coverage.xml
    --cov-report=term-missing
    --cov-fail-under=80

# Test markers for categorizing fallback tests
markers =
    fallback: marks tests as fallback system tests
    multi_level: marks tests as multi-level fallback chain tests
    performance: marks tests as performance/benchmark tests  
    integration: marks tests as integration tests
    stress: marks tests as stress/load tests
    simulation: marks tests as failure simulation tests
    recovery: marks tests as recovery mechanism tests
    monitoring: marks tests as monitoring/analytics tests
    edge_case: marks tests as edge case/boundary tests
    production: marks tests as production integration tests
    slow: marks tests as slow running tests (> 10 seconds)
    network: marks tests that require network/external dependencies
    
# Asyncio configuration
asyncio_mode = auto

# Timeout configuration  
timeout = 300
timeout_method = thread

# Warnings configuration
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:lightrag.*
    ignore::RuntimeWarning:asyncio.*

# Logging configuration during tests
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = logs/fallback_tests.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)d)
log_file_date_format = %Y-%m-%d %H:%M:%S

# Test collection
collect_ignore = [
    "setup.py",
    "venv",
    "lightrag_env", 
    "lightrag_test_env",
    ".git"
]

# Minimum Python version
minversion = 3.8

# Custom test execution order (if needed)
# Run critical fallback tests first, then performance tests
# Format: test_file::test_class::test_method or just test_file
custom_test_order = [
    "test_multi_level_fallback_scenarios.py::TestMultiLevelFallbackChain::test_successful_lightrag_primary_route",
    "test_multi_level_fallback_scenarios.py::TestMultiLevelFallbackChain::test_lightrag_failure_perplexity_fallback",
    "test_multi_level_fallback_scenarios.py::TestMultiLevelFallbackChain::test_lightrag_perplexity_both_fail_cache_fallback",
    "test_multi_level_fallback_scenarios.py::TestMultiLevelFallbackChain::test_complete_fallback_chain_failure_default_routing"
]