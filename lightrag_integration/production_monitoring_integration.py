"""
Production Monitoring Integration for Enhanced Load Detection
===========================================================

This module provides integration adapters between the enhanced load monitoring system
and the existing production monitoring infrastructure. It enables seamless data flow
and coordination between systems without requiring major architectural changes.

Key Features:
1. Bidirectional metrics sharing between systems
2. Backward compatibility with existing monitoring APIs
3. Enhanced metrics aggregation and correlation
4. Production-grade error handling and fallbacks
5. Performance optimization for high-throughput environments

Integration Points:
- ProductionMonitoring (production_monitoring.py)
- EnhancedLoadDetectionSystem (enhanced_load_monitoring_system.py)
- GracefulDegradationManager (graceful_degradation_system.py)
- ProductionLoadBalancer (production_load_balancer.py)

Author: Claude Code (Anthropic)
Version: 1.0.0
Created: 2025-08-09
Production Ready: Yes
"""

import asyncio
import logging
import time
import threading
from typing import Dict, List, Optional, Any, Union, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
from collections import defaultdict, deque

# Import enhanced monitoring components
try:
    from .enhanced_load_monitoring_system import (
        EnhancedLoadDetectionSystem,
        EnhancedSystemLoadMetrics,
        HysteresisConfig
    )
    ENHANCED_MONITORING_AVAILABLE = True
except ImportError:
    ENHANCED_MONITORING_AVAILABLE = False
    logging.warning("Enhanced monitoring system not available")

# Import production monitoring
try:
    from .production_monitoring import ProductionMonitoring
    PRODUCTION_MONITORING_AVAILABLE = True
except ImportError:
    PRODUCTION_MONITORING_AVAILABLE = False
    logging.warning("Production monitoring not available")

# Import graceful degradation system
try:
    from .graceful_degradation_system import (
        GracefulDegradationManager,
        SystemLoadLevel,
        LoadThresholds
    )
    GRACEFUL_DEGRADATION_AVAILABLE = True
except ImportError:
    GRACEFUL_DEGRADATION_AVAILABLE = False
    logging.warning("Graceful degradation system not available")


# ============================================================================
# INTEGRATION ADAPTERS
# ============================================================================

@dataclass
class IntegrationConfig:
    """Configuration for production monitoring integration."""
    
    # Synchronization settings
    sync_interval: float = 5.0
    bidirectional_sync: bool = True
    
    # Performance settings
    enable_metrics_caching: bool = True
    cache_ttl: float = 2.0
    batch_size: int = 100
    
    # Error handling
    max_sync_failures: int = 5
    fallback_mode_timeout: float = 30.0
    
    # Feature flags
    enable_enhanced_metrics: bool = True
    enable_trend_analysis: bool = True
    enable_predictive_alerts: bool = True


class ProductionMonitoringAdapter:
    """
    Adapter that bridges enhanced load monitoring with production monitoring system.
    
    Provides:
    - Bidirectional metrics synchronization
    - Legacy API compatibility
    - Enhanced metrics forwarding
    - Fallback mechanisms
    """
    
    def __init__(self,
                 production_monitoring: Any,
                 enhanced_detector: Optional[Any] = None,
                 config: Optional[IntegrationConfig] = None):
        
        self.production_monitoring = production_monitoring
        self.enhanced_detector = enhanced_detector
        self.config = config or IntegrationConfig()
        self.logger = logging.getLogger(__name__)
        
        # State tracking
        self._sync_active = False
        self._sync_task: Optional[asyncio.Task] = None
        self._sync_failures = 0
        self._fallback_mode = False
        self._last_sync_time = 0.0
        
        # Thread safety
        self._sync_lock = threading.Lock()
        
        # Metrics caching for performance
        self._metrics_cache: Dict[str, Any] = {}
        self._cache_timestamps: Dict[str, float] = {}\n        \n        # Integration state\n        self._integration_active = False\n        self._callbacks: List[Callable] = []\n        \n        # Register with production monitoring if possible\n        self._register_with_production_monitoring()\n        \n        self.logger.info(\"Production monitoring adapter initialized\")\n    \n    def _register_with_production_monitoring(self):\n        \"\"\"Register adapter with production monitoring system.\"\"\"\n        try:\n            if hasattr(self.production_monitoring, 'register_enhanced_adapter'):\n                self.production_monitoring.register_enhanced_adapter(self)\n                self.logger.info(\"Registered with production monitoring\")\n            elif hasattr(self.production_monitoring, 'register_external_monitor'):\n                self.production_monitoring.register_external_monitor(self)\n                self.logger.info(\"Registered as external monitor\")\n        except Exception as e:\n            self.logger.warning(f\"Failed to register with production monitoring: {e}\")\n    \n    async def start_integration(self):\n        \"\"\"Start the integration between monitoring systems.\"\"\"\n        if self._integration_active:\n            return\n        \n        self._integration_active = True\n        \n        # Start bidirectional sync if enabled\n        if self.config.bidirectional_sync:\n            self._sync_active = True\n            self._sync_task = asyncio.create_task(self._sync_loop())\n        \n        # Connect enhanced detector if available\n        if self.enhanced_detector:\n            self.enhanced_detector.add_load_change_callback(self._on_enhanced_metrics_update)\n        \n        self.logger.info(\"Production monitoring integration started\")\n    \n    async def stop_integration(self):\n        \"\"\"Stop the integration.\"\"\"\n        if not self._integration_active:\n            return\n        \n        self._integration_active = False\n        self._sync_active = False\n        \n        if self._sync_task:\n            self._sync_task.cancel()\n            try:\n                await self._sync_task\n            except asyncio.CancelledError:\n                pass\n        \n        self.logger.info(\"Production monitoring integration stopped\")\n    \n    async def _sync_loop(self):\n        \"\"\"Main synchronization loop.\"\"\"\n        while self._sync_active:\n            try:\n                current_time = time.time()\n                \n                # Perform bidirectional sync\n                if current_time - self._last_sync_time >= self.config.sync_interval:\n                    await self._perform_sync()\n                    self._last_sync_time = current_time\n                    self._sync_failures = 0  # Reset failure count on success\n                \n                await asyncio.sleep(1.0)  # Check every second\n                \n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                self._sync_failures += 1\n                self.logger.error(f\"Sync error (attempt {self._sync_failures}): {e}\")\n                \n                # Enter fallback mode if too many failures\n                if self._sync_failures >= self.config.max_sync_failures:\n                    await self._enter_fallback_mode()\n                \n                await asyncio.sleep(5.0)  # Wait longer after error\n    \n    async def _perform_sync(self):\n        \"\"\"Perform bidirectional synchronization between monitoring systems.\"\"\"\n        with self._sync_lock:\n            # Push enhanced metrics to production monitoring\n            await self._push_enhanced_metrics()\n            \n            # Pull production metrics for enhanced detector\n            await self._pull_production_metrics()\n            \n            # Synchronize alert thresholds\n            await self._sync_thresholds()\n    \n    async def _push_enhanced_metrics(self):\n        \"\"\"Push enhanced metrics to production monitoring system.\"\"\"\n        if not self.enhanced_detector or not self.enhanced_detector.current_metrics:\n            return\n        \n        try:\n            enhanced_metrics = self.enhanced_detector.current_metrics\n            \n            # Update basic system metrics\n            if hasattr(self.production_monitoring, 'update_system_metrics'):\n                self.production_monitoring.update_system_metrics(\n                    memory_usage_bytes=int(enhanced_metrics.memory_available_mb * 1024 * 1024),\n                    cpu_usage_percent=enhanced_metrics.cpu_utilization\n                )\n            \n            # Update enhanced metrics if supported\n            if hasattr(self.production_monitoring, 'update_enhanced_metrics'):\n                await self._update_enhanced_production_metrics(enhanced_metrics)\n            \n            # Update load balancer metrics if available\n            if hasattr(self.production_monitoring, 'update_load_balancer_metrics'):\n                self.production_monitoring.update_load_balancer_metrics(\n                    queue_depth=enhanced_metrics.request_queue_depth,\n                    active_connections=enhanced_metrics.active_connections,\n                    error_rate=enhanced_metrics.error_rate\n                )\n            \n            # Update performance metrics\n            if hasattr(self.production_monitoring, 'update_performance_metrics'):\n                self.production_monitoring.update_performance_metrics(\n                    response_time_p95=enhanced_metrics.response_time_p95,\n                    response_time_p99=enhanced_metrics.response_time_p99\n                )\n            \n        except Exception as e:\n            self.logger.error(f\"Error pushing enhanced metrics: {e}\")\n            raise\n    \n    async def _update_enhanced_production_metrics(self, metrics: Any):\n        \"\"\"Update production monitoring with enhanced metric details.\"\"\"\n        try:\n            # Prepare enhanced metrics payload\n            enhanced_payload = {\n                'timestamp': metrics.timestamp.isoformat(),\n                'load_level': metrics.load_level.name,\n                'load_score': metrics.load_score,\n                'cpu_per_core': metrics.cpu_per_core,\n                'swap_pressure': metrics.swap_pressure,\n                'response_time_p99_9': metrics.response_time_p99_9,\n                'network_latency_estimate': metrics.network_latency_estimate,\n                'error_categories': metrics.error_categories,\n                'trend_indicators': metrics.trend_indicators,\n                'hysteresis_factor_applied': metrics.hysteresis_factor_applied\n            }\n            \n            # Send to production monitoring\n            await self.production_monitoring.update_enhanced_metrics(enhanced_payload)\n            \n        except Exception as e:\n            self.logger.warning(f\"Error updating enhanced production metrics: {e}\")\n    \n    async def _pull_production_metrics(self):\n        \"\"\"Pull metrics from production monitoring to enhance detection.\"\"\"\n        if not self.enhanced_detector:\n            return\n        \n        try:\n            # Get production request queue depth\n            if hasattr(self.production_monitoring, 'get_request_queue_depth'):\n                queue_depth = await self._get_cached_metric(\n                    'queue_depth',\n                    self.production_monitoring.get_request_queue_depth\n                )\n                if queue_depth is not None:\n                    self.enhanced_detector.update_queue_depth(queue_depth)\n            \n            # Get production connection count\n            if hasattr(self.production_monitoring, 'get_active_connections'):\n                connections = await self._get_cached_metric(\n                    'active_connections',\n                    self.production_monitoring.get_active_connections\n                )\n                if connections is not None:\n                    self.enhanced_detector.update_connection_count(connections)\n            \n            # Get production error metrics\n            if hasattr(self.production_monitoring, 'get_error_metrics'):\n                error_metrics = await self._get_cached_metric(\n                    'error_metrics',\n                    self.production_monitoring.get_error_metrics\n                )\n                if error_metrics:\n                    await self._integrate_error_metrics(error_metrics)\n            \n            # Get production response time data\n            if hasattr(self.production_monitoring, 'get_response_time_data'):\n                response_data = await self._get_cached_metric(\n                    'response_times',\n                    self.production_monitoring.get_response_time_data\n                )\n                if response_data:\n                    await self._integrate_response_times(response_data)\n            \n        except Exception as e:\n            self.logger.error(f\"Error pulling production metrics: {e}\")\n            raise\n    \n    async def _get_cached_metric(self, metric_name: str, fetch_function: Callable) -> Any:\n        \"\"\"Get metric with caching to reduce overhead.\"\"\"\n        if not self.config.enable_metrics_caching:\n            return await self._safe_call(fetch_function)\n        \n        current_time = time.time()\n        cache_key = metric_name\n        \n        # Check cache validity\n        if (cache_key in self._metrics_cache and \n            current_time - self._cache_timestamps.get(cache_key, 0) < self.config.cache_ttl):\n            return self._metrics_cache[cache_key]\n        \n        # Fetch new value\n        try:\n            value = await self._safe_call(fetch_function)\n            if value is not None:\n                self._metrics_cache[cache_key] = value\n                self._cache_timestamps[cache_key] = current_time\n            return value\n        except Exception as e:\n            self.logger.warning(f\"Error fetching cached metric {metric_name}: {e}\")\n            return self._metrics_cache.get(cache_key)\n    \n    async def _safe_call(self, func: Callable) -> Any:\n        \"\"\"Safely call a function, handling both sync and async.\"\"\"\n        try:\n            if asyncio.iscoroutinefunction(func):\n                return await func()\n            else:\n                return func()\n        except Exception as e:\n            self.logger.warning(f\"Error in safe call: {e}\")\n            return None\n    \n    async def _integrate_error_metrics(self, error_metrics: Dict[str, Any]):\n        \"\"\"Integrate production error metrics into enhanced detector.\"\"\"\n        try:\n            if 'error_types' in error_metrics:\n                for error_type, count in error_metrics['error_types'].items():\n                    # Record errors in enhanced detector\n                    for _ in range(count):\n                        self.enhanced_detector.record_request_metrics(\n                            response_time_ms=0.0,  # No response time for errors\n                            error_type=error_type\n                        )\n        except Exception as e:\n            self.logger.warning(f\"Error integrating error metrics: {e}\")\n    \n    async def _integrate_response_times(self, response_data: Dict[str, Any]):\n        \"\"\"Integrate production response time data.\"\"\"\n        try:\n            if 'response_times' in response_data:\n                times = response_data['response_times']\n                # Batch process to avoid overwhelming the system\n                batch_size = min(self.config.batch_size, len(times))\n                for i in range(0, min(len(times), batch_size)):\n                    self.enhanced_detector.record_request_metrics(\n                        response_time_ms=times[i],\n                        error_type=None\n                    )\n        except Exception as e:\n            self.logger.warning(f\"Error integrating response times: {e}\")\n    \n    async def _sync_thresholds(self):\n        \"\"\"Synchronize alert thresholds between systems.\"\"\"\n        try:\n            # Get current thresholds from enhanced detector\n            if self.enhanced_detector and hasattr(self.enhanced_detector, 'thresholds'):\n                enhanced_thresholds = self.enhanced_detector.thresholds\n                \n                # Update production monitoring thresholds if supported\n                if hasattr(self.production_monitoring, 'update_alert_thresholds'):\n                    threshold_data = {\n                        'cpu_critical': enhanced_thresholds.cpu_critical,\n                        'memory_critical': enhanced_thresholds.memory_critical,\n                        'response_p95_critical': enhanced_thresholds.response_p95_critical,\n                        'error_rate_critical': enhanced_thresholds.error_rate_critical,\n                        'queue_depth_critical': enhanced_thresholds.queue_critical\n                    }\n                    \n                    await self._safe_call(\n                        lambda: self.production_monitoring.update_alert_thresholds(threshold_data)\n                    )\n        \n        except Exception as e:\n            self.logger.warning(f\"Error syncing thresholds: {e}\")\n    \n    def _on_enhanced_metrics_update(self, metrics: Any):\n        \"\"\"Handle updates from enhanced detector.\"\"\"\n        try:\n            # Trigger immediate sync for critical load levels\n            if metrics.load_level.value >= 3:  # CRITICAL or EMERGENCY\n                asyncio.create_task(self._perform_sync())\n            \n            # Notify callbacks\n            for callback in self._callbacks:\n                try:\n                    callback(metrics)\n                except Exception as e:\n                    self.logger.error(f\"Error in callback: {e}\")\n        \n        except Exception as e:\n            self.logger.error(f\"Error handling enhanced metrics update: {e}\")\n    \n    async def _enter_fallback_mode(self):\n        \"\"\"Enter fallback mode when sync failures exceed threshold.\"\"\"\n        self._fallback_mode = True\n        self.logger.warning(\"Entering fallback mode due to sync failures\")\n        \n        # Reduce sync frequency in fallback mode\n        original_interval = self.config.sync_interval\n        self.config.sync_interval = max(original_interval * 2, 30.0)\n        \n        # Schedule exit from fallback mode\n        await asyncio.sleep(self.config.fallback_mode_timeout)\n        \n        self._fallback_mode = False\n        self.config.sync_interval = original_interval\n        self._sync_failures = 0\n        \n        self.logger.info(\"Exited fallback mode\")\n    \n    def add_integration_callback(self, callback: Callable):\n        \"\"\"Add callback for integration events.\"\"\"\n        self._callbacks.append(callback)\n    \n    def get_integration_status(self) -> Dict[str, Any]:\n        \"\"\"Get current integration status.\"\"\"\n        return {\n            'active': self._integration_active,\n            'sync_active': self._sync_active,\n            'fallback_mode': self._fallback_mode,\n            'sync_failures': self._sync_failures,\n            'last_sync_time': datetime.fromtimestamp(self._last_sync_time).isoformat() if self._last_sync_time else None,\n            'enhanced_detector_available': self.enhanced_detector is not None,\n            'production_monitoring_available': self.production_monitoring is not None,\n            'cache_size': len(self._metrics_cache)\n        }\n\n\nclass GracefulDegradationIntegrator:\n    \"\"\"\n    Integrates enhanced load monitoring with graceful degradation manager.\n    \n    Provides seamless replacement of the basic load detector with enhanced version\n    while maintaining compatibility with existing degradation strategies.\n    \"\"\"\n    \n    def __init__(self,\n                 degradation_manager: Any,\n                 enhanced_detector: Optional[Any] = None,\n                 preserve_existing_callbacks: bool = True):\n        \n        self.degradation_manager = degradation_manager\n        self.enhanced_detector = enhanced_detector\n        self.preserve_existing_callbacks = preserve_existing_callbacks\n        self.logger = logging.getLogger(__name__)\n        \n        # State tracking\n        self._integration_complete = False\n        self._original_detector = None\n        \n    def integrate(self) -> bool:\n        \"\"\"Perform integration with graceful degradation manager.\"\"\"\n        try:\n            if not self.enhanced_detector or not self.degradation_manager:\n                self.logger.error(\"Missing required components for integration\")\n                return False\n            \n            # Store reference to original detector\n            if hasattr(self.degradation_manager, 'load_detector'):\n                self._original_detector = self.degradation_manager.load_detector\n            \n            # Replace detector with enhanced version\n            self.degradation_manager.load_detector = self.enhanced_detector\n            \n            # Transfer existing callbacks if requested\n            if (self.preserve_existing_callbacks and \n                self._original_detector and \n                hasattr(self._original_detector, '_callbacks')):\n                \n                for callback in self._original_detector._callbacks:\n                    # Wrap callback to handle enhanced metrics\n                    enhanced_callback = self._create_enhanced_callback(callback)\n                    self.enhanced_detector.add_load_change_callback(enhanced_callback)\n            \n            # Connect enhanced detector to degradation manager callbacks\n            if hasattr(self.degradation_manager, '_handle_load_change'):\n                enhanced_callback = self._create_degradation_callback(\n                    self.degradation_manager._handle_load_change\n                )\n                self.enhanced_detector.add_load_change_callback(enhanced_callback)\n            \n            self._integration_complete = True\n            self.logger.info(\"Successfully integrated enhanced detector with degradation manager\")\n            return True\n            \n        except Exception as e:\n            self.logger.error(f\"Error integrating with degradation manager: {e}\")\n            return False\n    \n    def _create_enhanced_callback(self, original_callback: Callable) -> Callable:\n        \"\"\"Create enhanced callback that converts enhanced metrics to basic format.\"\"\"\n        def enhanced_callback(enhanced_metrics: Any):\n            try:\n                # Convert enhanced metrics to basic format for compatibility\n                if hasattr(enhanced_metrics, 'to_base_metrics'):\n                    base_metrics = enhanced_metrics.to_base_metrics()\n                    original_callback(base_metrics)\n                else:\n                    # Direct call if already compatible\n                    original_callback(enhanced_metrics)\n            except Exception as e:\n                self.logger.error(f\"Error in enhanced callback wrapper: {e}\")\n        \n        return enhanced_callback\n    \n    def _create_degradation_callback(self, degradation_handler: Callable) -> Callable:\n        \"\"\"Create callback for degradation manager load change handler.\"\"\"\n        def degradation_callback(enhanced_metrics: Any):\n            try:\n                # Convert enhanced metrics for degradation manager\n                if hasattr(enhanced_metrics, 'to_base_metrics'):\n                    base_metrics = enhanced_metrics.to_base_metrics()\n                else:\n                    base_metrics = enhanced_metrics\n                \n                # Call degradation manager handler\n                degradation_handler(base_metrics)\n                \n            except Exception as e:\n                self.logger.error(f\"Error in degradation callback: {e}\")\n        \n        return degradation_callback\n    \n    def rollback(self) -> bool:\n        \"\"\"Rollback integration and restore original detector.\"\"\"\n        try:\n            if not self._integration_complete:\n                return True\n            \n            if self._original_detector and hasattr(self.degradation_manager, 'load_detector'):\n                self.degradation_manager.load_detector = self._original_detector\n                self._integration_complete = False\n                self.logger.info(\"Successfully rolled back integration\")\n                return True\n            \n            return False\n            \n        except Exception as e:\n            self.logger.error(f\"Error rolling back integration: {e}\")\n            return False\n    \n    def get_integration_status(self) -> Dict[str, Any]:\n        \"\"\"Get integration status information.\"\"\"\n        return {\n            'integration_complete': self._integration_complete,\n            'original_detector_preserved': self._original_detector is not None,\n            'enhanced_detector_active': (self._integration_complete and \n                                       hasattr(self.degradation_manager, 'load_detector') and \n                                       self.degradation_manager.load_detector is self.enhanced_detector)\n        }\n\n\n# ============================================================================\n# PRODUCTION INTEGRATION FACTORY\n# ============================================================================\n\ndef create_integrated_monitoring_system(\n    production_monitoring: Any,\n    degradation_manager: Optional[Any] = None,\n    integration_config: Optional[IntegrationConfig] = None,\n    hysteresis_config: Optional[HysteresisConfig] = None,\n    monitoring_interval: float = 5.0\n) -> Tuple[Any, ProductionMonitoringAdapter, Optional[GracefulDegradationIntegrator]]:\n    \"\"\"\n    Factory function to create fully integrated monitoring system.\n    \n    Returns:\n        Tuple of (enhanced_detector, adapter, degradation_integrator)\n    \"\"\"\n    \n    if not ENHANCED_MONITORING_AVAILABLE:\n        raise ImportError(\"Enhanced monitoring system not available\")\n    \n    # Create enhanced detector\n    enhanced_detector = EnhancedLoadDetectionSystem(\n        monitoring_interval=monitoring_interval,\n        production_monitoring=production_monitoring,\n        hysteresis_config=hysteresis_config or HysteresisConfig(),\n        enable_trend_analysis=True\n    )\n    \n    # Create production monitoring adapter\n    adapter = ProductionMonitoringAdapter(\n        production_monitoring=production_monitoring,\n        enhanced_detector=enhanced_detector,\n        config=integration_config or IntegrationConfig()\n    )\n    \n    # Create degradation integrator if degradation manager provided\n    degradation_integrator = None\n    if degradation_manager:\n        degradation_integrator = GracefulDegradationIntegrator(\n            degradation_manager=degradation_manager,\n            enhanced_detector=enhanced_detector\n        )\n    \n    return enhanced_detector, adapter, degradation_integrator\n\n\nasync def setup_complete_integration(\n    production_monitoring: Any,\n    degradation_manager: Optional[Any] = None,\n    integration_config: Optional[IntegrationConfig] = None\n) -> Dict[str, Any]:\n    \"\"\"\n    Set up complete integration between all monitoring systems.\n    \n    Returns integration components and status.\n    \"\"\"\n    \n    try:\n        # Create integrated system\n        enhanced_detector, adapter, degradation_integrator = create_integrated_monitoring_system(\n            production_monitoring=production_monitoring,\n            degradation_manager=degradation_manager,\n            integration_config=integration_config\n        )\n        \n        # Start enhanced monitoring\n        await enhanced_detector.start_monitoring()\n        \n        # Start production integration\n        await adapter.start_integration()\n        \n        # Integrate with degradation manager\n        degradation_integration_success = False\n        if degradation_integrator:\n            degradation_integration_success = degradation_integrator.integrate()\n        \n        return {\n            'success': True,\n            'enhanced_detector': enhanced_detector,\n            'adapter': adapter,\n            'degradation_integrator': degradation_integrator,\n            'degradation_integration_success': degradation_integration_success,\n            'adapter_status': adapter.get_integration_status(),\n            'degradation_status': degradation_integrator.get_integration_status() if degradation_integrator else None\n        }\n        \n    except Exception as e:\n        return {\n            'success': False,\n            'error': str(e),\n            'enhanced_detector': None,\n            'adapter': None,\n            'degradation_integrator': None\n        }\n\n\n# ============================================================================\n# DEMONSTRATION\n# ============================================================================\n\nasync def demonstrate_production_integration():\n    \"\"\"\n    Demonstrate the production monitoring integration.\n    \"\"\"\n    print(\"Production Monitoring Integration Demonstration\")\n    print(\"=\" * 60)\n    \n    # Mock production monitoring for demonstration\n    class MockProductionMonitoring:\n        def __init__(self):\n            self.system_metrics = {}\n            self.request_queue_depth = 10\n            self.active_connections = 50\n            \n        def update_system_metrics(self, memory_usage_bytes, cpu_usage_percent):\n            self.system_metrics = {\n                'memory': memory_usage_bytes,\n                'cpu': cpu_usage_percent,\n                'timestamp': datetime.now()\n            }\n            print(f\"Production monitoring updated: CPU={cpu_usage_percent:.1f}%, Memory={memory_usage_bytes/(1024*1024):.0f}MB\")\n        \n        def get_request_queue_depth(self):\n            return self.request_queue_depth\n        \n        def get_active_connections(self):\n            return self.active_connections\n    \n    # Create mock systems\n    mock_production_monitoring = MockProductionMonitoring()\n    \n    try:\n        # Create integrated monitoring system\n        if ENHANCED_MONITORING_AVAILABLE:\n            enhanced_detector, adapter, _ = create_integrated_monitoring_system(\n                production_monitoring=mock_production_monitoring,\n                integration_config=IntegrationConfig(sync_interval=2.0)\n            )\n            \n            # Add monitoring callback\n            def on_metrics_update(metrics):\n                print(f\"Enhanced metrics: Load={metrics.load_level.name}, CPU={metrics.cpu_utilization:.1f}%\")\n            \n            enhanced_detector.add_load_change_callback(on_metrics_update)\n            \n            # Start integration\n            await enhanced_detector.start_monitoring()\n            await adapter.start_integration()\n            \n            print(\"Integration started. Running for 20 seconds...\")\n            \n            # Simulate activity\n            for i in range(10):\n                await asyncio.sleep(2)\n                \n                # Simulate changing load\n                enhanced_detector.record_request_metrics(\n                    response_time_ms=200 + i * 100,\n                    error_type=\"timeout\" if i > 7 else None\n                )\n                enhanced_detector.update_queue_depth(5 + i * 3)\n                \n                # Update mock production system\n                mock_production_monitoring.request_queue_depth = 5 + i * 3\n                mock_production_monitoring.active_connections = 40 + i * 5\n            \n            # Stop integration\n            await adapter.stop_integration()\n            await enhanced_detector.stop_monitoring()\n            \n            # Show final status\n            print(\"\\nFinal Integration Status:\")\n            status = adapter.get_integration_status()\n            for key, value in status.items():\n                print(f\"  {key}: {value}\")\n        \n        else:\n            print(\"Enhanced monitoring system not available for demonstration\")\n    \n    except Exception as e:\n        print(f\"Error in demonstration: {e}\")\n\n\nif __name__ == \"__main__\":\n    # Run demonstration\n    asyncio.run(demonstrate_production_integration())