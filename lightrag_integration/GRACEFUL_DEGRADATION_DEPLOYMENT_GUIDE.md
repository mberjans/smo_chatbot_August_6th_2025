# Complete Graceful Degradation System - Production Deployment Guide

## Overview

This guide provides comprehensive instructions for deploying the complete graceful degradation system in the Clinical Metabolomics Oracle production environment. The system provides intelligent load-based request throttling and queuing mechanisms that complete the graceful degradation implementation.

## System Architecture

The graceful degradation system consists of four integrated components:

### 1. Enhanced Load Monitoring System
- **File**: `enhanced_load_monitoring_system.py`
- **Purpose**: Real-time system load detection with 5 load levels (NORMAL â†’ EMERGENCY)
- **Features**: CPU/memory monitoring, trend analysis, hysteresis for stability

### 2. Progressive Service Degradation Controller
- **File**: `progressive_service_degradation_controller.py`
- **Purpose**: Dynamic service optimization based on load level
- **Features**: Timeout management, query complexity reduction, feature control

### 3. Load-Based Request Throttling System
- **File**: `load_based_request_throttling_system.py`
- **Purpose**: Intelligent request management under high load
- **Features**: Token bucket throttling, priority queuing, connection pool management

### 4. Graceful Degradation Orchestrator
- **File**: `graceful_degradation_integration.py`
- **Purpose**: Unified coordination of all components
- **Features**: Production system integration, health monitoring, configuration sync

## Quick Start

### Basic Integration

```python
from graceful_degradation_integration import create_graceful_degradation_system

# Create the complete system
orchestrator = create_graceful_degradation_system()

# Start the system
await orchestrator.start()

# Submit requests through the integrated throttling system
success, message, request_id = await orchestrator.submit_request(
    request_type='user_query',
    priority='high',
    handler=your_query_handler,
    query="your metabolomics query here"
)

# Stop when done
await orchestrator.stop()
```

### Production Configuration

```python
from graceful_degradation_integration import (
    GracefulDegradationConfig, create_graceful_degradation_system
)

# Production-optimized configuration
config = GracefulDegradationConfig(
    # Monitoring settings
    monitoring_interval=5.0,              # 5-second intervals
    enable_trend_analysis=True,
    hysteresis_enabled=True,
    
    # Throttling settings
    base_rate_per_second=50.0,           # 50 requests/second base rate
    max_queue_size=2000,                 # Large queue for production
    max_concurrent_requests=100,         # High concurrency limit
    starvation_threshold=300.0,          # 5-minute anti-starvation
    
    # Connection pool settings
    base_pool_size=50,                   # 50 base connections
    max_pool_size=200,                   # Scale up to 200 connections
    
    # Production features
    auto_start_monitoring=True,
    enable_production_integration=True,
    metrics_retention_hours=24,
    
    # Emergency handling
    emergency_max_duration=300.0,        # 5-minute emergency limit
    auto_recovery_enabled=True,
    circuit_breaker_enabled=True
)

# Create with production systems
orchestrator = create_graceful_degradation_system(
    config=config,
    load_balancer=your_load_balancer,
    rag_system=your_rag_system,
    monitoring_system=your_monitoring_system
)
```

## Integration with Existing Systems

### Clinical Metabolomics RAG Integration

```python
from clinical_metabolomics_rag import ClinicalMetabolomicsRAG

# Your existing RAG system
rag_system = ClinicalMetabolomicsRAG()

# Create graceful degradation with RAG integration
orchestrator = create_graceful_degradation_system(
    rag_system=rag_system
)

# The system will automatically:
# - Update RAG timeouts based on load level
# - Adjust query complexity limits
# - Control feature availability
# - Monitor RAG performance
```

### Production Load Balancer Integration

```python
from production_load_balancer import ProductionLoadBalancer

# Your existing load balancer
load_balancer = ProductionLoadBalancer()

# Create graceful degradation with load balancer integration
orchestrator = create_graceful_degradation_system(
    load_balancer=load_balancer
)

# The system will automatically:
# - Update backend timeouts
# - Adjust circuit breaker settings
# - Coordinate request routing
# - Manage connection limits
```

## Request Types and Priorities

The system supports various request types with automatic priority assignment:

### Request Types
- `health_check`: System health verification (Priority: CRITICAL)
- `user_query`: Interactive user queries (Priority: HIGH)
- `batch_processing`: Batch data processing (Priority: MEDIUM)
- `analytics`: Reporting and analytics (Priority: LOW)
- `maintenance`: Background maintenance (Priority: BACKGROUND)
- `admin`: Administrative operations (Priority: HIGH)

### Custom Request Submission

```python
# Health check (highest priority)
await orchestrator.submit_request(
    request_type='health_check',
    handler=health_check_handler
)

# User query with custom priority
await orchestrator.submit_request(
    request_type='user_query',
    priority='critical',  # Override default priority
    handler=metabolomics_query_handler,
    query="analyze biomarker patterns"
)

# Background processing
await orchestrator.submit_request(
    request_type='batch_processing',
    handler=batch_processor,
    dataset_id="metabolomics_2024"
)
```

## Load Levels and System Behavior

### Load Level Progression

1. **NORMAL** (0-50% resource utilization)
   - Full functionality
   - No restrictions
   - Optimal performance

2. **ELEVATED** (50-65% resource utilization)
   - Minor optimizations
   - Reduced logging detail
   - 80% of normal rate limit

3. **HIGH** (65-80% resource utilization)
   - Timeout reductions (50% of normal)
   - Query complexity limits
   - 60% of normal rate limit
   - Some features disabled

4. **CRITICAL** (80-90% resource utilization)
   - Aggressive timeout cuts (33% of normal)
   - Significant feature disabling
   - 40% of normal rate limit
   - Priority processing only

5. **EMERGENCY** (>90% resource utilization)
   - Minimal functionality
   - Maximum degradation
   - 20% of normal rate limit
   - Critical requests only

### Automatic Adjustments by Load Level

| Component | NORMAL | ELEVATED | HIGH | CRITICAL | EMERGENCY |
|-----------|---------|----------|------|----------|-----------|
| Rate Limit | 100% | 80% | 60% | 40% | 20% |
| Queue Size | 100% | 80% | 60% | 40% | 20% |
| Connection Pool | 100% | 90% | 70% | 50% | 30% |
| LightRAG Timeout | 60s | 45s | 30s | 20s | 10s |
| OpenAI Timeout | 45s | 36s | 27s | 22s | 14s |
| Query Complexity | Full | Full | Limited | Simple | Minimal |

## Monitoring and Health Checks

### System Status Monitoring

```python
# Get comprehensive system status
status = orchestrator.get_system_status()
print(f"System Running: {status['running']}")
print(f"Current Load Level: {status['current_load_level']}")
print(f"Total Requests: {status['total_requests_processed']}")

# Get health check
health = orchestrator.get_health_check()
print(f"Health Status: {health['status']}")
print(f"Active Issues: {health['issues']}")
print(f"Component Status: {health['component_status']}")
```

### Metrics Collection

```python
# Get historical metrics
metrics_history = orchestrator.get_metrics_history(hours=4)
for metric in metrics_history:
    print(f"{metric['timestamp']}: {metric['load_level']} - "
          f"CPU: {metric['cpu_utilization']:.1f}%, "
          f"Memory: {metric['memory_pressure']:.1f}%")
```

### Health Check Callbacks

```python
# Add custom health monitoring
def custom_health_callback():
    health = orchestrator.get_health_check()
    if health['status'] == 'critical':
        # Send alert to monitoring system
        send_alert(f"System health critical: {health['issues']}")

orchestrator.add_health_check_callback(custom_health_callback)
```

## Performance Tuning

### Rate Limiting Optimization

```python
# Adjust base rate based on your traffic patterns
config = GracefulDegradationConfig(
    base_rate_per_second=100.0,  # High-traffic system
    burst_capacity=200,          # Allow bursts
)

# For lower traffic systems
config = GracefulDegradationConfig(
    base_rate_per_second=10.0,   # Lower base rate
    burst_capacity=20,           # Smaller bursts
)
```

### Queue Size Optimization

```python
# Large queue for high-variance workloads
config = GracefulDegradationConfig(
    max_queue_size=5000,         # Large queue
    starvation_threshold=600.0,  # 10-minute threshold
)

# Smaller queue for predictable workloads
config = GracefulDegradationConfig(
    max_queue_size=500,          # Smaller queue
    starvation_threshold=180.0,  # 3-minute threshold
)
```

### Connection Pool Tuning

```python
# High-concurrency configuration
config = GracefulDegradationConfig(
    base_pool_size=100,          # Large base pool
    max_pool_size=500,           # Very large max pool
    max_concurrent_requests=200, # High concurrency
)
```

## Testing and Validation

### Run Comprehensive Tests

```bash
# Run the comprehensive test suite
cd lightrag_integration
python -m pytest tests/test_load_based_throttling_comprehensive.py -v

# Run integration validation
python validate_throttling_integration.py

# Run complete system demonstration
python demo_complete_graceful_degradation.py
```

### Validate Production Integration

```python
# Validate integration with your production systems
from validate_throttling_integration import ValidationSuite

validation_suite = ValidationSuite()
report = await validation_suite.run_validation()

print(f"Validation Results:")
print(f"Success Rate: {report['validation_summary']['success_rate']:.1%}")
print(f"Component Availability: {report['component_availability']['availability_rate']:.1%}")
```

## Production Deployment Checklist

### Pre-Deployment

- [ ] All dependencies installed (`aiohttp`, `psutil`, `numpy`)
- [ ] Configuration optimized for your environment
- [ ] Integration with existing systems tested
- [ ] Load testing completed
- [ ] Monitoring and alerting configured
- [ ] Documentation and runbooks prepared

### Deployment Steps

1. **Install the graceful degradation system**
   ```bash
   # Copy all system files to your production environment
   cp enhanced_load_monitoring_system.py /path/to/production/
   cp progressive_service_degradation_controller.py /path/to/production/
   cp load_based_request_throttling_system.py /path/to/production/
   cp graceful_degradation_integration.py /path/to/production/
   ```

2. **Configure for your environment**
   ```python
   # Create production configuration
   config = GracefulDegradationConfig(
       monitoring_interval=5.0,
       base_rate_per_second=YOUR_RATE_LIMIT,
       max_queue_size=YOUR_QUEUE_SIZE,
       max_concurrent_requests=YOUR_CONCURRENCY_LIMIT
   )
   ```

3. **Initialize and start the system**
   ```python
   orchestrator = create_graceful_degradation_system(
       config=config,
       load_balancer=your_load_balancer,
       rag_system=your_rag_system,
       monitoring_system=your_monitoring_system
   )
   await orchestrator.start()
   ```

4. **Integrate with your application**
   ```python
   # Replace direct RAG calls with throttled requests
   # Old way:
   # result = await rag_system.query(user_query)
   
   # New way:
   success, message, request_id = await orchestrator.submit_request(
       request_type='user_query',
       handler=rag_system.query,
       query=user_query
   )
   ```

### Post-Deployment

- [ ] Monitor system health and performance
- [ ] Verify load level transitions work correctly
- [ ] Test emergency response scenarios
- [ ] Monitor request success rates
- [ ] Validate integration with existing systems
- [ ] Document any configuration adjustments needed

## Troubleshooting

### Common Issues

#### System Not Starting
```python
# Check component availability
from graceful_degradation_integration import (
    LOAD_MONITORING_AVAILABLE, DEGRADATION_CONTROLLER_AVAILABLE, 
    THROTTLING_SYSTEM_AVAILABLE
)

print(f"Load Monitoring: {LOAD_MONITORING_AVAILABLE}")
print(f"Degradation Controller: {DEGRADATION_CONTROLLER_AVAILABLE}")
print(f"Throttling System: {THROTTLING_SYSTEM_AVAILABLE}")
```

#### High Request Rejection Rate
```python
# Check throttling configuration
status = orchestrator.get_system_status()
throttling = status['throttling_system']['throttling']
print(f"Current Rate: {throttling['current_rate']}")
print(f"Success Rate: {throttling['success_rate']}")

# Increase rate limit if needed
config.base_rate_per_second = 100.0  # Increase from current value
```

#### Queue Overflows
```python
# Check queue utilization
status = orchestrator.get_system_status()
queue = status['throttling_system']['queue']
print(f"Queue Utilization: {queue['utilization']}%")
print(f"Queue Size: {queue['total_size']}/{queue['max_size']}")

# Increase queue size if needed
config.max_queue_size = 5000  # Increase from current value
```

### Performance Monitoring

```python
# Monitor key metrics regularly
def monitor_performance():
    health = orchestrator.get_health_check()
    status = orchestrator.get_system_status()
    
    # Alert conditions
    if health['status'] == 'critical':
        alert("System health critical!")
    
    throttling = status.get('throttling_system', {}).get('throttling', {})
    if throttling.get('success_rate', 100) < 90:
        alert(f"Low success rate: {throttling['success_rate']:.1f}%")
    
    queue = status.get('throttling_system', {}).get('queue', {})
    if queue.get('utilization', 0) > 90:
        alert(f"Queue near capacity: {queue['utilization']:.1f}%")

# Run monitoring every minute
import asyncio
async def monitoring_loop():
    while True:
        monitor_performance()
        await asyncio.sleep(60)
```

## Advanced Configuration

### Custom Load Thresholds

```python
from enhanced_load_monitoring_system import LoadThresholds

# Custom thresholds for your environment
custom_thresholds = LoadThresholds(
    cpu_normal=40.0,      # More aggressive CPU threshold
    cpu_elevated=55.0,
    cpu_high=70.0,
    cpu_critical=80.0,
    cpu_emergency=90.0,
    
    memory_normal=50.0,   # More aggressive memory threshold
    memory_elevated=60.0,
    memory_high=70.0,
    memory_critical=80.0,
    memory_emergency=85.0,
    
    # Custom response time thresholds based on your SLAs
    response_p95_normal=500.0,    # 500ms SLA
    response_p95_elevated=1000.0,
    response_p95_high=2000.0,
    response_p95_critical=3000.0,
    response_p95_emergency=5000.0
)

# Use custom thresholds
enhanced_detector = create_enhanced_load_monitoring_system(
    thresholds=custom_thresholds
)
```

### Custom Request Handlers

```python
# Create specialized request handlers
class MetabolomicsRequestHandler:
    async def handle_pathway_analysis(self, pathway_data):
        # Custom pathway analysis logic
        await asyncio.sleep(2.0)  # Simulate processing time
        return f"Analyzed pathway: {pathway_data['name']}"
    
    async def handle_biomarker_search(self, search_terms):
        # Custom biomarker search logic
        await asyncio.sleep(1.5)
        return f"Found biomarkers for: {search_terms}"

handler = MetabolomicsRequestHandler()

# Submit specialized requests
await orchestrator.submit_request(
    request_type='user_query',
    priority='high',
    handler=handler.handle_pathway_analysis,
    pathway_data={'name': 'glycolysis', 'organism': 'human'}
)
```

## Security Considerations

### Request Validation

```python
# Add request validation
def validate_request(request_data):
    # Implement your security checks
    if not request_data.get('user_id'):
        raise ValueError("User ID required")
    
    if len(request_data.get('query', '')) > 10000:
        raise ValueError("Query too long")
    
    return True

# Use validation in request handlers
async def secure_query_handler(query, user_id):
    validate_request({'query': query, 'user_id': user_id})
    return await process_query(query)
```

### Rate Limiting by User

```python
from collections import defaultdict
import time

class UserRateLimiter:
    def __init__(self, requests_per_minute=60):
        self.requests_per_minute = requests_per_minute
        self.user_requests = defaultdict(list)
    
    def can_process_request(self, user_id):
        now = time.time()
        cutoff = now - 60  # 1 minute ago
        
        # Clean old requests
        self.user_requests[user_id] = [
            req_time for req_time in self.user_requests[user_id]
            if req_time > cutoff
        ]
        
        # Check limit
        if len(self.user_requests[user_id]) >= self.requests_per_minute:
            return False
        
        # Record this request
        self.user_requests[user_id].append(now)
        return True

user_limiter = UserRateLimiter(requests_per_minute=100)

# Use in request submission
if user_limiter.can_process_request(user_id):
    await orchestrator.submit_request(...)
else:
    return "Rate limit exceeded for user"
```

## Conclusion

The complete graceful degradation system provides production-ready intelligent request management for the Clinical Metabolomics Oracle. It automatically adapts to system load conditions, ensuring optimal performance and system stability under varying traffic patterns.

Key benefits:
- **Intelligent Load Management**: Automatic adaptation to system load
- **Request Prioritization**: Critical requests processed first
- **System Protection**: Prevents overload and maintains stability
- **Production Integration**: Seamless integration with existing systems
- **Comprehensive Monitoring**: Real-time health and performance monitoring

The system is ready for immediate production deployment and will significantly improve the reliability and performance of the Clinical Metabolomics Oracle under varying load conditions.

## Support and Maintenance

For ongoing support:

1. **Monitor** system health regularly using the built-in health checks
2. **Tune** configuration based on actual traffic patterns
3. **Update** thresholds based on system performance observations
4. **Test** emergency scenarios periodically
5. **Review** logs and metrics for optimization opportunities

The system is designed to be self-managing but benefits from periodic review and tuning based on actual usage patterns in your production environment.