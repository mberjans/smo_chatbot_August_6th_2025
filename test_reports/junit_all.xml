<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="15" failures="33" skipped="0" tests="322" time="26.638" timestamp="2025-08-07T20:21:49.768954-06:00" hostname="Marks-MacBook-Pro-7.local"><testcase classname="test_feature_flag_manager.TestFeatureFlagManagerInitialization" name="test_initialization_with_valid_config" time="0.003" /><testcase classname="test_feature_flag_manager.TestFeatureFlagManagerInitialization" name="test_initialization_with_invalid_config" time="0.001" /><testcase classname="test_feature_flag_manager.TestFeatureFlagManagerInitialization" name="test_initialization_creates_default_logger" time="0.001" /><testcase classname="test_feature_flag_manager.TestFeatureFlagManagerInitialization" name="test_routing_rules_parsing" time="0.002" /><testcase classname="test_feature_flag_manager.TestHashBasedUserAssignment" name="test_calculate_user_hash_consistency" time="0.002" /><testcase classname="test_feature_flag_manager.TestHashBasedUserAssignment" name="test_calculate_user_hash_different_users" time="0.002" /><testcase classname="test_feature_flag_manager.TestHashBasedUserAssignment" name="test_calculate_user_hash_uses_salt" time="0.002" /><testcase classname="test_feature_flag_manager.TestHashBasedUserAssignment" name="test_get_rollout_percentage_from_hash" time="0.002" /><testcase classname="test_feature_flag_manager.TestHashBasedUserAssignment" name="test_rollout_percentage_distribution" time="0.003" /><testcase classname="test_feature_flag_manager.TestUserCohortAssignment" name="test_assign_user_cohort_simple_rollout" time="0.003" /><testcase classname="test_feature_flag_manager.TestUserCohortAssignment" name="test_assign_user_cohort_ab_testing" time="0.002" /><testcase classname="test_feature_flag_manager.TestUserCohortAssignment" name="test_user_cohort_assignment_caching" time="0.002" /><testcase classname="test_feature_flag_manager.TestUserCohortAssignment" name="test_user_cohort_assignment_consistency" time="0.002" /><testcase classname="test_feature_flag_manager.TestCircuitBreakerFunctionality" name="test_circuit_breaker_initially_closed" time="0.002" /><testcase classname="test_feature_flag_manager.TestCircuitBreakerFunctionality" name="test_circuit_breaker_disabled" time="0.002" /><testcase classname="test_feature_flag_manager.TestCircuitBreakerFunctionality" name="test_circuit_breaker_opens_on_failures" time="0.002" /><testcase classname="test_feature_flag_manager.TestCircuitBreakerFunctionality" name="test_circuit_breaker_recovery_timeout" time="0.002" /><testcase classname="test_feature_flag_manager.TestCircuitBreakerFunctionality" name="test_circuit_breaker_recovery_not_ready" time="0.002" /><testcase classname="test_feature_flag_manager.TestConditionalRoutingRules" name="test_conditional_routing_disabled" time="0.002" /><testcase classname="test_feature_flag_manager.TestConditionalRoutingRules" name="test_query_length_rule" time="0.002" /><testcase classname="test_feature_flag_manager.TestConditionalRoutingRules" name="test_query_complexity_rule" time="0.002" /><testcase classname="test_feature_flag_manager.TestConditionalRoutingRules" name="test_query_type_rule" time="0.002" /><testcase classname="test_feature_flag_manager.TestConditionalRoutingRules" name="test_rule_evaluation_error_handling" time="0.002" /><testcase classname="test_feature_flag_manager.TestQualityThresholdValidation" name="test_quality_threshold_disabled" time="0.002" /><testcase classname="test_feature_flag_manager.TestQualityThresholdValidation" name="test_quality_threshold_no_data" time="0.002" /><testcase classname="test_feature_flag_manager.TestQualityThresholdValidation" name="test_quality_threshold_above_minimum" time="0.002" /><testcase classname="test_feature_flag_manager.TestQualityThresholdValidation" name="test_quality_threshold_below_minimum" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingDecisionLogic" name="test_routing_integration_disabled" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingDecisionLogic" name="test_routing_forced_cohort" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingDecisionLogic" name="test_routing_circuit_breaker_open" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingDecisionLogic" name="test_routing_quality_threshold_failed" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingDecisionLogic" name="test_routing_conditional_rule_failed" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingDecisionLogic" name="test_routing_successful_lightrag" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingDecisionLogic" name="test_routing_successful_perplexity" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingDecisionLogic" name="test_routing_with_ab_testing" time="0.002" /><testcase classname="test_feature_flag_manager.TestPerformanceMetricsTracking" name="test_record_success_lightrag" time="0.002" /><testcase classname="test_feature_flag_manager.TestPerformanceMetricsTracking" name="test_record_success_perplexity" time="0.002" /><testcase classname="test_feature_flag_manager.TestPerformanceMetricsTracking" name="test_record_failure_lightrag" time="0.002" /><testcase classname="test_feature_flag_manager.TestPerformanceMetricsTracking" name="test_record_failure_perplexity" time="0.002" /><testcase classname="test_feature_flag_manager.TestPerformanceMetricsTracking" name="test_circuit_breaker_failure_recovery" time="0.002" /><testcase classname="test_feature_flag_manager.TestPerformanceMetricsTracking" name="test_metrics_memory_management" time="0.006" /><testcase classname="test_feature_flag_manager.TestCachingAndOptimization" name="test_routing_result_caching" time="0.002" /><testcase classname="test_feature_flag_manager.TestCachingAndOptimization" name="test_routing_cache_expiration" time="0.002" /><testcase classname="test_feature_flag_manager.TestCachingAndOptimization" name="test_cache_size_management" time="0.017" /><testcase classname="test_feature_flag_manager.TestCachingAndOptimization" name="test_cohort_cache_consistency" time="0.002" /><testcase classname="test_feature_flag_manager.TestPerformanceSummaryAndReporting" name="test_get_performance_summary_structure" time="0.002" /><testcase classname="test_feature_flag_manager.TestPerformanceSummaryAndReporting" name="test_performance_metrics_calculation" time="0.002" /><testcase classname="test_feature_flag_manager.TestPerformanceSummaryAndReporting" name="test_circuit_breaker_metrics" time="0.002" /><testcase classname="test_feature_flag_manager.TestUtilityMethods" name="test_reset_circuit_breaker" time="0.002" /><testcase classname="test_feature_flag_manager.TestUtilityMethods" name="test_clear_caches" time="0.002" /><testcase classname="test_feature_flag_manager.TestUtilityMethods" name="test_update_rollout_percentage_valid" time="0.002" /><testcase classname="test_feature_flag_manager.TestUtilityMethods" name="test_update_rollout_percentage_invalid" time="0.002" /><testcase classname="test_feature_flag_manager.TestThreadSafetyAndConcurrency" name="test_concurrent_routing_decisions" time="0.004" /><testcase classname="test_feature_flag_manager.TestThreadSafetyAndConcurrency" name="test_thread_safe_metrics_recording" time="0.003" /><testcase classname="test_feature_flag_manager.TestThreadSafetyAndConcurrency" name="test_thread_safe_cache_operations" time="0.006" /><testcase classname="test_feature_flag_manager.TestErrorHandlingAndEdgeCases" name="test_routing_with_none_user_id" time="0.002" /><testcase classname="test_feature_flag_manager.TestErrorHandlingAndEdgeCases" name="test_routing_with_empty_query" time="0.002" /><testcase classname="test_feature_flag_manager.TestErrorHandlingAndEdgeCases" name="test_routing_with_exception_handling" time="0.002" /><testcase classname="test_feature_flag_manager.TestErrorHandlingAndEdgeCases" name="test_performance_metrics_with_zero_data" time="0.002" /><testcase classname="test_feature_flag_manager.TestErrorHandlingAndEdgeCases" name="test_circuit_breaker_state_with_zero_requests" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingResultSerialization" name="test_routing_result_to_dict" time="0.002" /><testcase classname="test_feature_flag_manager.TestRoutingResultSerialization" name="test_routing_result_serialization_completeness" time="0.000" /><testcase classname="test_integration_wrapper.TestServiceResponse" name="test_service_response_initialization" time="0.001" /><testcase classname="test_integration_wrapper.TestServiceResponse" name="test_service_response_is_success_true" time="0.000" /><testcase classname="test_integration_wrapper.TestServiceResponse" name="test_service_response_is_success_false_empty_content" time="0.000" /><testcase classname="test_integration_wrapper.TestServiceResponse" name="test_service_response_is_success_false_with_error" time="0.000" /><testcase classname="test_integration_wrapper.TestServiceResponse" name="test_service_response_average_quality_score" time="0.001"><failure message="AssertionError: assert 0.7999999999999999 == 0.8000000000000002&#10; +  where 0.7999999999999999 = ServiceResponse(content='Test content', citations=None, confidence_scores=None, response_type=&lt;ResponseType.PERPLEXITY: 'perplexity'&gt;, processing_time=0.0, quality_scores={&lt;QualityMetric.RELEVANCE: 'relevance'&gt;: 0.8, &lt;QualityMetric.ACCURACY: 'accuracy'&gt;: 0.9, &lt;QualityMetric.COMPLETENESS: 'completeness'&gt;: 0.7}, metadata={}, error_details=None, service_info={}).average_quality_score">lightrag_integration/tests/test_integration_wrapper.py:118: in test_service_response_average_quality_score
    assert response.average_quality_score == expected_average
E   AssertionError: assert 0.7999999999999999 == 0.8000000000000002
E    +  where 0.7999999999999999 = ServiceResponse(content='Test content', citations=None, confidence_scores=None, response_type=&lt;ResponseType.PERPLEXITY: 'perplexity'&gt;, processing_time=0.0, quality_scores={&lt;QualityMetric.RELEVANCE: 'relevance'&gt;: 0.8, &lt;QualityMetric.ACCURACY: 'accuracy'&gt;: 0.9, &lt;QualityMetric.COMPLETENESS: 'completeness'&gt;: 0.7}, metadata={}, error_details=None, service_info={}).average_quality_score</failure></testcase><testcase classname="test_integration_wrapper.TestServiceResponse" name="test_service_response_average_quality_score_no_scores" time="0.001" /><testcase classname="test_integration_wrapper.TestServiceResponse" name="test_service_response_to_dict" time="0.001" /><testcase classname="test_integration_wrapper.TestQueryRequest" name="test_query_request_initialization" time="0.001" /><testcase classname="test_integration_wrapper.TestQueryRequest" name="test_query_request_to_routing_context" time="0.000" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_perplexity_service_initialization" time="0.040" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_get_service_name" time="0.005" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_is_available_with_api_key" time="0.005" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_is_available_without_api_key" time="0.005" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_query_async_successful" time="0.008" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_query_async_api_error" time="0.006" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_query_async_exception" time="0.011" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_process_perplexity_response" time="0.006" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_health_check_success" time="0.006" /><testcase classname="test_integration_wrapper.TestPerplexityQueryService" name="test_health_check_failure" time="0.006" /><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_lightrag_service_initialization" time="0.002" /><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_get_service_name" time="0.002" /><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_is_available_not_initialized" time="0.002" /><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_ensure_initialized_success" time="0.002"><failure message="AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'LightRAG'">lightrag_integration/tests/test_integration_wrapper.py:371: in test_ensure_initialized_success
    with patch('lightrag_integration.integration_wrapper.LightRAG', return_value=mock_lightrag_instance), \
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'LightRAG'</failure></testcase><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_ensure_initialized_failure" time="0.002"><failure message="AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'LightRAG'">lightrag_integration/tests/test_integration_wrapper.py:385: in test_ensure_initialized_failure
    with patch('lightrag_integration.integration_wrapper.LightRAG', side_effect=Exception("Import failed")):
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'LightRAG'</failure></testcase><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_query_async_initialization_failed" time="0.003" /><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_query_async_successful" time="0.003"><failure message="AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'QueryParam'">lightrag_integration/tests/test_integration_wrapper.py:410: in test_query_async_successful
    patch('lightrag_integration.integration_wrapper.QueryParam'), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'QueryParam'</failure></testcase><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_query_async_timeout" time="0.003"><failure message="AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'QueryParam'">lightrag_integration/tests/test_integration_wrapper.py:428: in test_query_async_timeout
    patch('lightrag_integration.integration_wrapper.QueryParam'), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'QueryParam'</failure></testcase><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_query_async_empty_response" time="0.003"><failure message="AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'QueryParam'">lightrag_integration/tests/test_integration_wrapper.py:446: in test_query_async_empty_response
    patch('lightrag_integration.integration_wrapper.QueryParam'), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'lightrag_integration.integration_wrapper' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/integration_wrapper.py'&gt; does not have the attribute 'QueryParam'</failure></testcase><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_health_check_not_initialized" time="0.003" /><testcase classname="test_integration_wrapper.TestLightRAGQueryService" name="test_health_check_success" time="0.002" /><testcase classname="test_integration_wrapper.TestAdvancedCircuitBreaker" name="test_circuit_breaker_initialization" time="0.001" /><testcase classname="test_integration_wrapper.TestAdvancedCircuitBreaker" name="test_circuit_breaker_successful_call" time="0.001" /><testcase classname="test_integration_wrapper.TestAdvancedCircuitBreaker" name="test_circuit_breaker_failure_tracking" time="0.002" /><testcase classname="test_integration_wrapper.TestAdvancedCircuitBreaker" name="test_circuit_breaker_open_state" time="0.002" /><testcase classname="test_integration_wrapper.TestAdvancedCircuitBreaker" name="test_circuit_breaker_recovery" time="0.002" /><testcase classname="test_integration_wrapper.TestAdvancedCircuitBreaker" name="test_circuit_breaker_get_state" time="0.001" /><testcase classname="test_integration_wrapper.TestServiceHealthMonitor" name="test_health_monitor_initialization" time="0.001" /><testcase classname="test_integration_wrapper.TestServiceHealthMonitor" name="test_register_service" time="0.002" /><testcase classname="test_integration_wrapper.TestServiceHealthMonitor" name="test_health_monitoring_cycle" time="0.002" /><testcase classname="test_integration_wrapper.TestServiceHealthMonitor" name="test_health_monitoring_failure" time="0.002" /><testcase classname="test_integration_wrapper.TestServiceHealthMonitor" name="test_health_monitoring_exception" time="0.002" /><testcase classname="test_integration_wrapper.TestServiceHealthMonitor" name="test_get_service_health" time="0.002" /><testcase classname="test_integration_wrapper.TestServiceHealthMonitor" name="test_get_all_health_status" time="0.002" /><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_integrated_service_initialization" time="0.003"><failure message="AttributeError: Mock object has no attribute 'lightrag_routing_rules'">lightrag_integration/tests/test_integration_wrapper.py:763: in test_integrated_service_initialization
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:757: in __init__
    self.feature_manager = FeatureFlagManager(config=config, logger=self.logger)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
lightrag_integration/feature_flag_manager.py:226: in __init__
    self.routing_rules = self._parse_routing_rules(config.lightrag_routing_rules or {})
                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:690: in __getattr__
    raise AttributeError("Mock object has no attribute %r" % name)
E   AttributeError: Mock object has no attribute 'lightrag_routing_rules'</failure></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_set_quality_assessor" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_query_async_lightrag_success" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_query_async_perplexity_success" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_query_async_fallback_mechanism" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_query_async_cache_hit" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_query_async_timeout_handling" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_query_async_exception_handling" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_generate_cache_key" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_cache_response_and_retrieval" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_cache_expiration" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_cache_size_management" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_get_performance_summary" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_get_ab_test_metrics_empty" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_clear_cache" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestIntegratedQueryService" name="test_shutdown" time="0.004"><error message="failed on setup with &quot;RuntimeError: no running event loop&quot;">lightrag_integration/tests/test_integration_wrapper.py:736: in integrated_service
    service = IntegratedQueryService(
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</error></testcase><testcase classname="test_integration_wrapper.TestFactoryFunctions" name="test_create_integrated_service" time="0.001" /><testcase classname="test_integration_wrapper.TestFactoryFunctions" name="test_create_perplexity_only_service" time="0.001" /><testcase classname="test_integration_wrapper.TestFactoryFunctions" name="test_create_lightrag_only_service" time="0.001" /><testcase classname="test_integration_wrapper.TestFactoryFunctions" name="test_managed_query_service_context_manager" time="0.002" /><testcase classname="test_integration_wrapper.TestIntegrationErrorHandling" name="test_both_services_fail" time="0.004"><failure message="assert &quot;IntegratedQueryService error: 'str' object has no attribute 'value'&quot; == 'LightRAG failed'&#10;  &#10;  - LightRAG failed&#10;  + IntegratedQueryService error: 'str' object has no attribute 'value'">lightrag_integration/tests/test_integration_wrapper.py:1122: in test_both_services_fail
    assert response.error_details == "LightRAG failed"
E   assert "IntegratedQueryService error: 'str' object has no attribute 'value'" == 'LightRAG failed'
E     
E     - LightRAG failed
E     + IntegratedQueryService error: 'str' object has no attribute 'value'</failure></testcase><testcase classname="test_integration_wrapper.TestIntegrationErrorHandling" name="test_circuit_breaker_blocks_request" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_default_feature_flag_values" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[true-True]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[True-True]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[TRUE-True]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[1-True]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[yes-True]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[YES-True]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[t-True]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[on-True]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[ON-True]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[false-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[False-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[FALSE-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[0-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[no-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[NO-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[f-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[off-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[OFF-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[invalid-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_boolean_environment_variable_parsing[-False]" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_numeric_environment_variables" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_string_environment_variables" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_json_environment_variables" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_invalid_json_environment_variable" time="0.001"><failure message="json.decoder.JSONDecodeError: Expecting value: line 1 column 13 (char 12)">lightrag_integration/tests/test_feature_flag_configuration.py:166: in test_invalid_json_environment_variable
    config = LightRAGConfig()
             ^^^^^^^^^^^^^^^^
&lt;string&gt;:47: in __init__
    ???
lightrag_integration/config.py:115: in &lt;lambda&gt;
    lightrag_routing_rules: Optional[Dict[str, Any]] = field(default_factory=lambda: json.loads(os.getenv("LIGHTRAG_ROUTING_RULES", "{}")) if os.getenv("LIGHTRAG_ROUTING_RULES") else None)
                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:346: in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:363: in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
E   json.decoder.JSONDecodeError: Expecting value: line 1 column 13 (char 12)</failure></testcase><testcase classname="test_feature_flag_configuration.TestFeatureFlagEnvironmentVariables" name="test_missing_environment_variables_use_defaults" time="0.001"><failure message="AssertionError: assert None == {}&#10; +  where None = LightRAGConfig(api_key='***masked***', model='gpt-4o-mini', embedding_model='text-embedding-3-small', working_dir=Path('/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025'), graph_storage_dir=Path('/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag'), max_async=16, max_tokens=32768, auto_create_dirs=True, log_level='WARNING', log_dir=Path('logs'), enable_file_logging=False, log_max_bytes=10485760, log_backup_count=5, log_filename='lightrag_integration.log', enable_cost_tracking=True, daily_budget_limit=None, monthly_budget_limit=None, cost_db_path=Path('/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/cost_tracking.db')).lightrag_routing_rules">lightrag_integration/tests/test_feature_flag_configuration.py:197: in test_missing_environment_variables_use_defaults
    assert config.lightrag_routing_rules == {}
E   AssertionError: assert None == {}
E    +  where None = LightRAGConfig(api_key='***masked***', model='gpt-4o-mini', embedding_model='text-embedding-3-small', working_dir=Path('/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025'), graph_storage_dir=Path('/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag'), max_async=16, max_tokens=32768, auto_create_dirs=True, log_level='WARNING', log_dir=Path('logs'), enable_file_logging=False, log_max_bytes=10485760, log_backup_count=5, log_filename='lightrag_integration.log', enable_cost_tracking=True, daily_budget_limit=None, monthly_budget_limit=None, cost_db_path=Path('/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/cost_tracking.db')).lightrag_routing_rules</failure></testcase><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_rollout_percentage_validation_negative" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_rollout_percentage_validation_above_100" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_rollout_percentage_validation_valid_range" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_user_cohort_validation_valid_values" time="0.002" /><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_user_cohort_validation_invalid_values" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_timeout_validation_positive" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_timeout_validation_zero_or_negative" time="0.002" /><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_quality_threshold_validation_range" time="0.004" /><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_circuit_breaker_threshold_validation" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationValidation" name="test_circuit_breaker_recovery_timeout_validation" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationFactoryMethods" name="test_config_from_environment_variables" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationFactoryMethods" name="test_config_with_custom_parameters" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationFactoryMethods" name="test_config_parameter_override_environment" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationSerialization" name="test_config_to_dict_feature_flags_included" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationSerialization" name="test_config_secure_representation" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationErrorHandling" name="test_invalid_numeric_environment_variable" time="0.001"><failure message="ValueError: could not convert string to float: 'not_a_number'">lightrag_integration/tests/test_feature_flag_configuration.py:413: in test_invalid_numeric_environment_variable
    config = LightRAGConfig()
             ^^^^^^^^^^^^^^^^
&lt;string&gt;:34: in __init__
    ???
lightrag_integration/config.py:102: in &lt;lambda&gt;
    lightrag_rollout_percentage: float = field(default_factory=lambda: float(os.getenv("LIGHTRAG_ROLLOUT_PERCENTAGE", "0.0")))
                                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: could not convert string to float: 'not_a_number'</failure></testcase><testcase classname="test_feature_flag_configuration.TestConfigurationErrorHandling" name="test_empty_environment_variables" time="0.001"><failure message="AssertionError: assert '' == 'cmo_lightrag_2025'&#10;  &#10;  - cmo_lightrag_2025">lightrag_integration/tests/test_feature_flag_configuration.py:429: in test_empty_environment_variables
    assert config.lightrag_user_hash_salt == "cmo_lightrag_2025"
E   AssertionError: assert '' == 'cmo_lightrag_2025'
E     
E     - cmo_lightrag_2025</failure></testcase><testcase classname="test_feature_flag_configuration.TestConfigurationErrorHandling" name="test_malformed_json_routing_rules" time="0.001"><failure message="json.decoder.JSONDecodeError: Expecting value: line 1 column 14 (char 13)">lightrag_integration/tests/test_feature_flag_configuration.py:439: in test_malformed_json_routing_rules
    config = LightRAGConfig()
             ^^^^^^^^^^^^^^^^
&lt;string&gt;:47: in __init__
    ???
lightrag_integration/config.py:115: in &lt;lambda&gt;
    lightrag_routing_rules: Optional[Dict[str, Any]] = field(default_factory=lambda: json.loads(os.getenv("LIGHTRAG_ROUTING_RULES", "{}")) if os.getenv("LIGHTRAG_ROUTING_RULES") else None)
                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:346: in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:363: in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
E   json.decoder.JSONDecodeError: Expecting value: line 1 column 14 (char 13)</failure></testcase><testcase classname="test_feature_flag_configuration.TestConfigurationErrorHandling" name="test_extremely_large_numeric_values" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagInteractions" name="test_ab_testing_requires_integration_enabled" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagInteractions" name="test_circuit_breaker_with_zero_rollout" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagInteractions" name="test_conditional_routing_without_rules" time="0.001" /><testcase classname="test_feature_flag_configuration.TestFeatureFlagInteractions" name="test_quality_metrics_with_zero_threshold" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationCompleteIntegration" name="test_production_feature_flag_configuration" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationCompleteIntegration" name="test_development_feature_flag_configuration" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationCompleteIntegration" name="test_testing_feature_flag_configuration" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationEdgeCasesAndCornerCases" name="test_unicode_in_environment_variables" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationEdgeCasesAndCornerCases" name="test_very_long_environment_variables" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationEdgeCasesAndCornerCases" name="test_whitespace_in_environment_variables" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationEdgeCasesAndCornerCases" name="test_scientific_notation_in_numeric_values" time="0.001" /><testcase classname="test_feature_flag_configuration.TestConfigurationEdgeCasesAndCornerCases" name="test_boundary_value_analysis" time="0.004" /><testcase classname="test_conditional_imports.TestFeatureFlagLoading" name="test_feature_flags_loaded_on_import" time="0.000" /><testcase classname="test_conditional_imports.TestFeatureFlagLoading" name="test_feature_flag_detection_functions" time="0.000" /><testcase classname="test_conditional_imports.TestFeatureFlagLoading" name="test_feature_enabled_detection" time="0.002" /><testcase classname="test_conditional_imports.TestFeatureFlagLoading" name="test_feature_disabled_detection" time="0.002" /><testcase classname="test_conditional_imports.TestFeatureFlagLoading" name="test_get_enabled_features_returns_dict" time="0.001" /><testcase classname="test_conditional_imports.TestConditionalImports" name="test_core_components_always_available" time="0.001" /><testcase classname="test_conditional_imports.TestConditionalImports" name="test_conditional_import_disabled_feature" time="0.002" /><testcase classname="test_conditional_imports.TestConditionalImports" name="test_conditional_import_enabled_feature" time="0.002"><failure message="assert None is not None&#10; +  where None = lightrag_integration.RelevanceScorer">lightrag_integration/tests/test_conditional_imports.py:150: in test_conditional_import_enabled_feature
    assert lightrag_integration.RelevanceScorer is not None
E   assert None is not None
E    +  where None = lightrag_integration.RelevanceScorer</failure></testcase><testcase classname="test_conditional_imports.TestConditionalImports" name="test_import_error_graceful_handling" time="0.001"><failure message="Failed: Import error should be handled gracefully">lightrag_integration/tests/test_conditional_imports.py:158: in test_import_error_graceful_handling
    importlib.reload(lightrag_integration)
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py:129: in reload
    _bootstrap._exec(spec, module)
&lt;frozen importlib._bootstrap&gt;:866: in _exec
    ???
&lt;frozen importlib._bootstrap_external&gt;:1022: in exec_module
    ???
&lt;frozen importlib._bootstrap_external&gt;:1118: in get_code
    ???
&lt;frozen importlib._bootstrap_external&gt;:1217: in get_data
    ???
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1169: in __call__
    return self._mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1173: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1228: in _execute_mock_call
    raise effect
E   ImportError: Module not found

During handling of the above exception, another exception occurred:
lightrag_integration/tests/test_conditional_imports.py:160: in test_import_error_graceful_handling
    pytest.fail("Import error should be handled gracefully")
E   Failed: Import error should be handled gracefully</failure></testcase><testcase classname="test_conditional_imports.TestConditionalImports" name="test_feature_flag_import_consistency" time="0.001"><failure message="assert None is not None&#10; +  where None = lightrag_integration.EnhancedResponseQualityAssessor">lightrag_integration/tests/test_conditional_imports.py:175: in test_feature_flag_import_consistency
    assert lightrag_integration.EnhancedResponseQualityAssessor is not None
E   assert None is not None
E    +  where None = lightrag_integration.EnhancedResponseQualityAssessor</failure></testcase><testcase classname="test_conditional_imports.TestDynamicExports" name="test_all_export_list_exists" time="0.001" /><testcase classname="test_conditional_imports.TestDynamicExports" name="test_core_exports_always_present" time="0.000" /><testcase classname="test_conditional_imports.TestDynamicExports" name="test_conditional_exports_based_on_features" time="0.000" /><testcase classname="test_conditional_imports.TestDynamicExports" name="test_exports_match_available_objects" time="0.001" /><testcase classname="test_conditional_imports.TestIntegrationStatus" name="test_get_integration_status_structure" time="0.001" /><testcase classname="test_conditional_imports.TestIntegrationStatus" name="test_module_status_information" time="0.001" /><testcase classname="test_conditional_imports.TestIntegrationStatus" name="test_integration_health_calculation" time="0.000" /><testcase classname="test_conditional_imports.TestIntegrationStatus" name="test_validate_integration_setup" time="0.001" /><testcase classname="test_conditional_imports.TestModuleRegistrationAndAvailability" name="test_integration_modules_registered" time="0.001" /><testcase classname="test_conditional_imports.TestModuleRegistrationAndAvailability" name="test_module_availability_checking" time="0.000" /><testcase classname="test_conditional_imports.TestModuleRegistrationAndAvailability" name="test_factory_function_registration" time="0.000" /><testcase classname="test_conditional_imports.TestGracefulDegradation" name="test_missing_optional_modules" time="0.002" /><testcase classname="test_conditional_imports.TestGracefulDegradation" name="test_partial_feature_availability" time="0.001" /><testcase classname="test_conditional_imports.TestGracefulDegradation" name="test_error_logging_for_import_failures" time="0.001"><failure message="AttributeError: &lt;module 'lightrag_integration' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/__init__.py'&gt; does not have the attribute 'logging'">lightrag_integration/tests/test_conditional_imports.py:399: in test_error_logging_for_import_failures
    with patch('lightrag_integration.logging') as mock_logging:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: &lt;module 'lightrag_integration' from '/Users/Mark/Research/Clinical_Metabolomics_Oracle/smo_chatbot_August_6th_2025/lightrag_integration/__init__.py'&gt; does not have the attribute 'logging'</failure></testcase><testcase classname="test_conditional_imports.TestFactoryFunctionAvailability" name="test_core_factory_functions_available" time="0.001" /><testcase classname="test_conditional_imports.TestFactoryFunctionAvailability" name="test_conditional_factory_functions" time="0.000" /><testcase classname="test_conditional_imports.TestFactoryFunctionAvailability" name="test_factory_function_error_handling" time="0.000" /><testcase classname="test_conditional_imports.TestEnvironmentVariableIntegration" name="test_environment_variable_feature_control" time="0.002" /><testcase classname="test_conditional_imports.TestEnvironmentVariableIntegration" name="test_default_feature_states" time="0.002" /><testcase classname="test_conditional_imports.TestEnvironmentVariableIntegration" name="test_invalid_environment_values_handled" time="0.002" /><testcase classname="test_conditional_imports.TestModuleInitializationRobustness" name="test_multiple_imports" time="0.000" /><testcase classname="test_conditional_imports.TestModuleInitializationRobustness" name="test_import_error_recovery" time="0.001" /><testcase classname="test_conditional_imports.TestModuleInitializationRobustness" name="test_circular_import_protection" time="0.000" /><testcase classname="test_conditional_imports.TestExportConsistency" name="test_all_exports_importable" time="0.000" /><testcase classname="test_conditional_imports.TestExportConsistency" name="test_no_unexpected_none_exports" time="0.000" /><testcase classname="test_conditional_imports.TestExportConsistency" name="test_export_type_consistency" time="0.000" /><testcase classname="test_feature_flag_integration.TestCompleteQueryWorkflows" name="test_lightrag_routing_complete_workflow" time="0.001"><failure message="TypeError: cannot unpack non-iterable async_generator object">lightrag_integration/tests/test_feature_flag_integration.py:106: in test_lightrag_routing_complete_workflow
    service, mock_perplexity, mock_lightrag = integrated_test_service
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: cannot unpack non-iterable async_generator object</failure></testcase><testcase classname="test_feature_flag_integration.TestCompleteQueryWorkflows" name="test_perplexity_routing_complete_workflow" time="0.001"><failure message="TypeError: cannot unpack non-iterable async_generator object">lightrag_integration/tests/test_feature_flag_integration.py:159: in test_perplexity_routing_complete_workflow
    service, mock_perplexity, mock_lightrag = integrated_test_service
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: cannot unpack non-iterable async_generator object</failure></testcase><testcase classname="test_feature_flag_integration.TestCompleteQueryWorkflows" name="test_fallback_workflow_lightrag_to_perplexity" time="0.001"><failure message="TypeError: cannot unpack non-iterable async_generator object">lightrag_integration/tests/test_feature_flag_integration.py:205: in test_fallback_workflow_lightrag_to_perplexity
    service, mock_perplexity, mock_lightrag = integrated_test_service
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: cannot unpack non-iterable async_generator object</failure></testcase><testcase classname="test_feature_flag_integration.TestABTestingIntegration" name="test_ab_testing_cohort_consistency" time="0.004" /><testcase classname="test_feature_flag_integration.TestABTestingIntegration" name="test_ab_testing_distribution" time="0.019" /><testcase classname="test_feature_flag_integration.TestABTestingIntegration" name="test_ab_testing_metrics_collection" time="0.003" /><testcase classname="test_feature_flag_integration.TestCircuitBreakerIntegration" name="test_circuit_breaker_failure_accumulation" time="0.003"><failure message="AssertionError: assert (False or 'lightrag' == 'perplexity'&#10; +  where False = &lt;built-in method get of dict object at 0x10be38200&gt;('circuit_breaker_blocked', False)&#10; +    where &lt;built-in method get of dict object at 0x10be38200&gt; = {'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': None, 'routing_confidence': 0.95, 'fallback_used': True, 'total_processing_time': 0.00030422210693359375}.get&#10; +      where {'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': None, 'routing_confidence': 0.95, 'fallback_used': True, 'total_processing_time': 0.00030422210693359375} = ServiceResponse(content='Perplexity fallback response', citations=None, confidence_scores=None, response_type=&lt;ResponseType.CACHED: 'cached'&gt;, processing_time=0.0, quality_scores=None, metadata={'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': None, 'routing_confidence': 0.95, 'fallback_used': True, 'total_processing_time': 0.00030422210693359375}, error_details=None, service_info={}).metadata&#10;  &#10;  - perplexity&#10;  + lightrag)">lightrag_integration/tests/test_feature_flag_integration.py:426: in test_circuit_breaker_failure_accumulation
    assert response.metadata.get('circuit_breaker_blocked', False) or \
E   AssertionError: assert (False or 'lightrag' == 'perplexity'
E    +  where False = &lt;built-in method get of dict object at 0x10be38200&gt;('circuit_breaker_blocked', False)
E    +    where &lt;built-in method get of dict object at 0x10be38200&gt; = {'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': None, 'routing_confidence': 0.95, 'fallback_used': True, 'total_processing_time': 0.00030422210693359375}.get
E    +      where {'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': None, 'routing_confidence': 0.95, 'fallback_used': True, 'total_processing_time': 0.00030422210693359375} = ServiceResponse(content='Perplexity fallback response', citations=None, confidence_scores=None, response_type=&lt;ResponseType.CACHED: 'cached'&gt;, processing_time=0.0, quality_scores=None, metadata={'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': None, 'routing_confidence': 0.95, 'fallback_used': True, 'total_processing_time': 0.00030422210693359375}, error_details=None, service_info={}).metadata
E     
E     - perplexity
E     + lightrag)</failure></testcase><testcase classname="test_feature_flag_integration.TestCircuitBreakerIntegration" name="test_circuit_breaker_recovery_workflow" time="0.001" /><testcase classname="test_feature_flag_integration.TestQualityThresholdIntegration" name="test_quality_threshold_routing_decision" time="0.001" /><testcase classname="test_feature_flag_integration.TestQualityThresholdIntegration" name="test_quality_threshold_recovery" time="0.001"><failure message="AssertionError: assert (&lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt; == &lt;RoutingDecision.LIGHTRAG: 'lightrag'&gt; or &lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt; != &lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt;)&#10; +  where &lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt; = RoutingResult(decision=&lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt;, reason=&lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt;, user_cohort=None, confidence=0.8, rollout_hash=None, circuit_breaker_state=None, quality_score=0.6, processing_time_ms=0.052928924560546875, metadata={}).decision&#10; +  and   &lt;RoutingDecision.LIGHTRAG: 'lightrag'&gt; = RoutingDecision.LIGHTRAG&#10; +  and   &lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt; = RoutingResult(decision=&lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt;, reason=&lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt;, user_cohort=None, confidence=0.8, rollout_hash=None, circuit_breaker_state=None, quality_score=0.6, processing_time_ms=0.052928924560546875, metadata={}).reason&#10; +  and   &lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt; = RoutingReason.QUALITY_THRESHOLD">lightrag_integration/tests/test_feature_flag_integration.py:498: in test_quality_threshold_recovery
    assert result2.decision == RoutingDecision.LIGHTRAG or result2.reason != RoutingReason.QUALITY_THRESHOLD
E   AssertionError: assert (&lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt; == &lt;RoutingDecision.LIGHTRAG: 'lightrag'&gt; or &lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt; != &lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt;)
E    +  where &lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt; = RoutingResult(decision=&lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt;, reason=&lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt;, user_cohort=None, confidence=0.8, rollout_hash=None, circuit_breaker_state=None, quality_score=0.6, processing_time_ms=0.052928924560546875, metadata={}).decision
E    +  and   &lt;RoutingDecision.LIGHTRAG: 'lightrag'&gt; = RoutingDecision.LIGHTRAG
E    +  and   &lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt; = RoutingResult(decision=&lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt;, reason=&lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt;, user_cohort=None, confidence=0.8, rollout_hash=None, circuit_breaker_state=None, quality_score=0.6, processing_time_ms=0.052928924560546875, metadata={}).reason
E    +  and   &lt;RoutingReason.QUALITY_THRESHOLD: 'quality_threshold'&gt; = RoutingReason.QUALITY_THRESHOLD</failure></testcase><testcase classname="test_feature_flag_integration.TestConditionalRoutingIntegration" name="test_conditional_routing_rule_evaluation" time="0.001"><failure message="AssertionError: assert &lt;RoutingReason.USER_COHORT_ASSIGNMENT: 'user_cohort_assignment'&gt; == &lt;RoutingReason.CONDITIONAL_RULE: 'conditional_rule'&gt;&#10; +  where &lt;RoutingReason.USER_COHORT_ASSIGNMENT: 'user_cohort_assignment'&gt; = RoutingResult(decision=&lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt;, reason=&lt;RoutingReason.USER_COHORT_ASSIGNMENT: 'user_cohort_assignment'&gt;, user_cohort=&lt;UserCohort.PERPLEXITY: 'perplexity'&gt;, confidence=0.95, rollout_hash='520b1d82ca1f4d24', circuit_breaker_state='closed', quality_score=None, processing_time_ms=0.09083747863769531, metadata={'rollout_percentage_achieved': 73.74776263575717, 'rollout_threshold': 100.0, 'rule_triggered': 'length_rule'}).reason&#10; +  and   &lt;RoutingReason.CONDITIONAL_RULE: 'conditional_rule'&gt; = RoutingReason.CONDITIONAL_RULE">lightrag_integration/tests/test_feature_flag_integration.py:546: in test_conditional_routing_rule_evaluation
    assert result2.reason == RoutingReason.CONDITIONAL_RULE
E   AssertionError: assert &lt;RoutingReason.USER_COHORT_ASSIGNMENT: 'user_cohort_assignment'&gt; == &lt;RoutingReason.CONDITIONAL_RULE: 'conditional_rule'&gt;
E    +  where &lt;RoutingReason.USER_COHORT_ASSIGNMENT: 'user_cohort_assignment'&gt; = RoutingResult(decision=&lt;RoutingDecision.PERPLEXITY: 'perplexity'&gt;, reason=&lt;RoutingReason.USER_COHORT_ASSIGNMENT: 'user_cohort_assignment'&gt;, user_cohort=&lt;UserCohort.PERPLEXITY: 'perplexity'&gt;, confidence=0.95, rollout_hash='520b1d82ca1f4d24', circuit_breaker_state='closed', quality_score=None, processing_time_ms=0.09083747863769531, metadata={'rollout_percentage_achieved': 73.74776263575717, 'rollout_threshold': 100.0, 'rule_triggered': 'length_rule'}).reason
E    +  and   &lt;RoutingReason.CONDITIONAL_RULE: 'conditional_rule'&gt; = RoutingReason.CONDITIONAL_RULE</failure></testcase><testcase classname="test_feature_flag_integration.TestCacheIntegrationWorkflows" name="test_response_caching_across_requests" time="0.007"><failure message="AssertionError: assert 2.0 &lt; 2.0&#10; +  where 2.0 = ServiceResponse(content='First response', citations=None, confidence_scores=None, response_type=&lt;ResponseType.CACHED: 'cached'&gt;, processing_time=2.0, quality_scores=None, metadata={'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': 'lightrag', 'routing_confidence': 0.95, 'fallback_used': False, 'total_processing_time': 0.00012803077697753906}, error_details=None, service_info={}).processing_time&#10; +  and   2.0 = ServiceResponse(content='First response', citations=None, confidence_scores=None, response_type=&lt;ResponseType.CACHED: 'cached'&gt;, processing_time=2.0, quality_scores=None, metadata={'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': 'lightrag', 'routing_confidence': 0.95, 'fallback_used': False, 'total_processing_time': 0.00012803077697753906}, error_details=None, service_info={}).processing_time">lightrag_integration/tests/test_feature_flag_integration.py:594: in test_response_caching_across_requests
    assert response2.processing_time &lt; response1.processing_time
E   AssertionError: assert 2.0 &lt; 2.0
E    +  where 2.0 = ServiceResponse(content='First response', citations=None, confidence_scores=None, response_type=&lt;ResponseType.CACHED: 'cached'&gt;, processing_time=2.0, quality_scores=None, metadata={'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': 'lightrag', 'routing_confidence': 0.95, 'fallback_used': False, 'total_processing_time': 0.00012803077697753906}, error_details=None, service_info={}).processing_time
E    +  and   2.0 = ServiceResponse(content='First response', citations=None, confidence_scores=None, response_type=&lt;ResponseType.CACHED: 'cached'&gt;, processing_time=2.0, quality_scores=None, metadata={'routing_decision': 'lightrag', 'routing_reason': 'user_cohort_assignment', 'user_cohort': 'lightrag', 'routing_confidence': 0.95, 'fallback_used': False, 'total_processing_time': 0.00012803077697753906}, error_details=None, service_info={}).processing_time</failure></testcase><testcase classname="test_feature_flag_integration.TestCacheIntegrationWorkflows" name="test_routing_cache_consistency" time="0.001" /><testcase classname="test_feature_flag_integration.TestMultiUserScenarios" name="test_concurrent_user_routing_consistency" time="0.003" /><testcase classname="test_feature_flag_integration.TestMultiUserScenarios" name="test_user_cohort_distribution_stability" time="0.105" /><testcase classname="test_feature_flag_integration.TestMultiUserScenarios" name="test_mixed_user_query_patterns" time="0.005" /><testcase classname="test_feature_flag_integration.TestRealWorldUsagePatterns" name="test_gradual_rollout_simulation" time="0.012"><failure message="AssertionError: Rollout 50.0%: expected ~50.0%, got 32.0%&#10;assert 18.0 &lt;= 10.0&#10; +  where 18.0 = abs((32.0 - 50.0))">lightrag_integration/tests/test_feature_flag_integration.py:789: in test_gradual_rollout_simulation
    assert abs(actual_percentage - rollout_pct) &lt;= tolerance, \
E   AssertionError: Rollout 50.0%: expected ~50.0%, got 32.0%
E   assert 18.0 &lt;= 10.0
E    +  where 18.0 = abs((32.0 - 50.0))</failure></testcase><testcase classname="test_feature_flag_integration.TestRealWorldUsagePatterns" name="test_high_load_performance_stability" time="0.014"><failure message="AssertionError: Unexpected routing distribution: 0.22&#10;assert 0.3 &lt;= 0.22">lightrag_integration/tests/test_feature_flag_integration.py:835: in test_high_load_performance_stability
    assert 0.3 &lt;= lightrag_ratio &lt;= 0.7, f"Unexpected routing distribution: {lightrag_ratio}"
E   AssertionError: Unexpected routing distribution: 0.22
E   assert 0.3 &lt;= 0.22</failure></testcase><testcase classname="test_feature_flag_integration.TestRealWorldUsagePatterns" name="test_error_recovery_scenarios" time="0.002" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[-1.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[-100.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[-0.001]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[0.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[0.001]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[0.1]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[99.9]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[99.999]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[100.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[100.001]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[150.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_rollout_percentage_boundary_values[1000.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[-1.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[-0.5]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[-0.001]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[0.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[0.001]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[0.1]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[0.9]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[0.999]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[1.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[1.001]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[1.5]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_quality_threshold_boundary_values[10.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_circuit_breaker_failure_threshold_boundary[0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_circuit_breaker_failure_threshold_boundary[-1]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_circuit_breaker_failure_threshold_boundary[-5]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_circuit_breaker_failure_threshold_boundary[1]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_circuit_breaker_failure_threshold_boundary[2]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_circuit_breaker_failure_threshold_boundary[100]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_circuit_breaker_failure_threshold_boundary[1000]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[-10.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[-1.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[0.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[0.001]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[0.1]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[1.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[30.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[60.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[300.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[3600.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestBoundaryValueEdgeCases" name="test_timeout_boundary_values[86400.0]" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestHashingEdgeCases" name="test_hash_calculation_extreme_user_ids" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestHashingEdgeCases" name="test_hash_consistency_across_calls" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestHashingEdgeCases" name="test_hash_distribution_uniformity" time="0.018" /><testcase classname="test_feature_flag_edge_cases.TestCircuitBreakerEdgeCases" name="test_circuit_breaker_at_exact_threshold" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestCircuitBreakerEdgeCases" name="test_circuit_breaker_just_below_threshold" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestCircuitBreakerEdgeCases" name="test_circuit_breaker_recovery_at_exact_timeout" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestCircuitBreakerEdgeCases" name="test_circuit_breaker_rapid_failure_recovery_cycles" time="1.047" /><testcase classname="test_feature_flag_edge_cases.TestCircuitBreakerEdgeCases" name="test_advanced_circuit_breaker_edge_cases" time="0.212" /><testcase classname="test_feature_flag_edge_cases.TestMemoryAndCacheEdgeCases" name="test_routing_cache_memory_limits" time="0.120" /><testcase classname="test_feature_flag_edge_cases.TestMemoryAndCacheEdgeCases" name="test_performance_metrics_memory_management" time="0.008" /><testcase classname="test_feature_flag_edge_cases.TestMemoryAndCacheEdgeCases" name="test_cache_cleanup_under_memory_pressure" time="0.002"><failure message="RuntimeError: no running event loop">lightrag_integration/tests/test_feature_flag_edge_cases.py:376: in test_cache_cleanup_under_memory_pressure
    service = IntegratedQueryService(config=config, perplexity_api_key="test")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</failure></testcase><testcase classname="test_feature_flag_edge_cases.TestMemoryAndCacheEdgeCases" name="test_concurrent_cache_access_edge_cases" time="0.002" /><testcase classname="test_feature_flag_edge_cases.TestErrorHandlingAndRecovery" name="test_routing_with_corrupted_config" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestErrorHandlingAndRecovery" name="test_service_initialization_failures" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestErrorHandlingAndRecovery" name="test_hash_calculation_with_invalid_salt" time="0.001" /><testcase classname="test_feature_flag_edge_cases.TestErrorHandlingAndRecovery" name="test_network_timeout_edge_cases" time="0.527"><failure message="assert 'timeout' in 'perplexity api error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 authorization required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 authorization required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentdocument||a.contentwindow.document;if(b){var d=b.createelement(\'script\');d.innerhtml=&quot;window.__cf$cv$params={r:\'96bb8afe6af28420\',t:\'mtc1ndyxotcxnc4wmdawmda=\'};var a=document.createelement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getelementsbytagname(\'head\')[0].appendchild(a);&quot;;b.getelementsbytagname(\'head\')[0].appendchild(d)}}if(document.body){var a=document.createelement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendchild(a);if(\'loading\'!==document.readystate)c();else if(window.addeventlistener)document.addeventlistener(\'domcontentloaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readystate&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n'&#10; +  where 'perplexity api error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 authorization required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 authorization required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentdocument||a.contentwindow.document;if(b){var d=b.createelement(\'script\');d.innerhtml=&quot;window.__cf$cv$params={r:\'96bb8afe6af28420\',t:\'mtc1ndyxotcxnc4wmdawmda=\'};var a=document.createelement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getelementsbytagname(\'head\')[0].appendchild(a);&quot;;b.getelementsbytagname(\'head\')[0].appendchild(d)}}if(document.body){var a=document.createelement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendchild(a);if(\'loading\'!==document.readystate)c();else if(window.addeventlistener)document.addeventlistener(\'domcontentloaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readystate&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n' = &lt;built-in method lower of str object at 0x127815800&gt;()&#10; +    where &lt;built-in method lower of str object at 0x127815800&gt; = 'Perplexity API error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement(\'script\');d.innerHTML=&quot;window.__CF$cv$params={r:\'96bb8afe6af28420\',t:\'MTc1NDYxOTcxNC4wMDAwMDA=\'};var a=document.createElement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getElementsByTagName(\'head\')[0].appendChild(a);&quot;;b.getElementsByTagName(\'head\')[0].appendChild(d)}}if(document.body){var a=document.createElement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendChild(a);if(\'loading\'!==document.readyState)c();else if(window.addEventListener)document.addEventListener(\'DOMContentLoaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readyState&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n'.lower&#10; +      where 'Perplexity API error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement(\'script\');d.innerHTML=&quot;window.__CF$cv$params={r:\'96bb8afe6af28420\',t:\'MTc1NDYxOTcxNC4wMDAwMDA=\'};var a=document.createElement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getElementsByTagName(\'head\')[0].appendChild(a);&quot;;b.getElementsByTagName(\'head\')[0].appendChild(d)}}if(document.body){var a=document.createElement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendChild(a);if(\'loading\'!==document.readyState)c();else if(window.addEventListener)document.addEventListener(\'DOMContentLoaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readyState&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n' = ServiceResponse(content='Service temporarily unavailable. Please try again later.', citations=None, confidence_scores=None, response_type=&lt;ResponseType.CIRCUIT_BREAKER_BLOCKED: 'circuit_breaker_blocked'&gt;, processing_time=0.0, quality_scores=None, metadata={'circuit_breaker': 'open', 'routing_decision': 'perplexity', 'routing_reason': 'user_cohort_assignment', 'user_cohort': 'control', 'routing_confidence': 0.95, 'fallback_used': False, 'total_processing_time': 0.5172758102416992}, error_details='Perplexity API error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement(\'script\');d.innerHTML=&quot;window.__CF$cv$params={r:\'96bb8afe6af28420\',t:\'MTc1NDYxOTcxNC4wMDAwMDA=\'};var a=document.createElement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getElementsByTagName(\'head\')[0].appendChild(a);&quot;;b.getElementsByTagName(\'head\')[0].appendChild(d)}}if(document.body){var a=document.createElement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendChild(a);if(\'loading\'!==document.readyState)c();else if(window.addEventListener)document.addEventListener(\'DOMContentLoaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readyState&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n', service_info={}).error_details">lightrag_integration/tests/test_feature_flag_edge_cases.py:510: in test_network_timeout_edge_cases
    assert "timeout" in response.error_details.lower()
E   assert 'timeout' in 'perplexity api error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 authorization required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 authorization required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentdocument||a.contentwindow.document;if(b){var d=b.createelement(\'script\');d.innerhtml="window.__cf$cv$params={r:\'96bb8afe6af28420\',t:\'mtc1ndyxotcxnc4wmdawmda=\'};var a=document.createelement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getelementsbytagname(\'head\')[0].appendchild(a);";b.getelementsbytagname(\'head\')[0].appendchild(d)}}if(document.body){var a=document.createelement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendchild(a);if(\'loading\'!==document.readystate)c();else if(window.addeventlistener)document.addeventlistener(\'domcontentloaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readystate&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n'
E    +  where 'perplexity api error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 authorization required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 authorization required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentdocument||a.contentwindow.document;if(b){var d=b.createelement(\'script\');d.innerhtml="window.__cf$cv$params={r:\'96bb8afe6af28420\',t:\'mtc1ndyxotcxnc4wmdawmda=\'};var a=document.createelement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getelementsbytagname(\'head\')[0].appendchild(a);";b.getelementsbytagname(\'head\')[0].appendchild(d)}}if(document.body){var a=document.createelement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendchild(a);if(\'loading\'!==document.readystate)c();else if(window.addeventlistener)document.addeventlistener(\'domcontentloaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readystate&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n' = &lt;built-in method lower of str object at 0x127815800&gt;()
E    +    where &lt;built-in method lower of str object at 0x127815800&gt; = 'Perplexity API error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement(\'script\');d.innerHTML="window.__CF$cv$params={r:\'96bb8afe6af28420\',t:\'MTc1NDYxOTcxNC4wMDAwMDA=\'};var a=document.createElement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getElementsByTagName(\'head\')[0].appendChild(a);";b.getElementsByTagName(\'head\')[0].appendChild(d)}}if(document.body){var a=document.createElement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendChild(a);if(\'loading\'!==document.readyState)c();else if(window.addEventListener)document.addEventListener(\'DOMContentLoaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readyState&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n'.lower
E    +      where 'Perplexity API error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement(\'script\');d.innerHTML="window.__CF$cv$params={r:\'96bb8afe6af28420\',t:\'MTc1NDYxOTcxNC4wMDAwMDA=\'};var a=document.createElement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getElementsByTagName(\'head\')[0].appendChild(a);";b.getElementsByTagName(\'head\')[0].appendChild(d)}}if(document.body){var a=document.createElement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendChild(a);if(\'loading\'!==document.readyState)c();else if(window.addEventListener)document.addEventListener(\'DOMContentLoaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readyState&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n' = ServiceResponse(content='Service temporarily unavailable. Please try again later.', citations=None, confidence_scores=None, response_type=&lt;ResponseType.CIRCUIT_BREAKER_BLOCKED: 'circuit_breaker_blocked'&gt;, processing_time=0.0, quality_scores=None, metadata={'circuit_breaker': 'open', 'routing_decision': 'perplexity', 'routing_reason': 'user_cohort_assignment', 'user_cohort': 'control', 'routing_confidence': 0.95, 'fallback_used': False, 'total_processing_time': 0.5172758102416992}, error_details='Perplexity API error 401: &lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;\r\n&lt;body&gt;\r\n&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;\r\n&lt;hr&gt;&lt;center&gt;openresty/1.27.4&lt;/center&gt;\r\n&lt;script&gt;(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement(\'script\');d.innerHTML="window.__CF$cv$params={r:\'96bb8afe6af28420\',t:\'MTc1NDYxOTcxNC4wMDAwMDA=\'};var a=document.createElement(\'script\');a.nonce=\'\';a.src=\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\';document.getElementsByTagName(\'head\')[0].appendChild(a);";b.getElementsByTagName(\'head\')[0].appendChild(d)}}if(document.body){var a=document.createElement(\'iframe\');a.height=1;a.width=1;a.style.position=\'absolute\';a.style.top=0;a.style.left=0;a.style.border=\'none\';a.style.visibility=\'hidden\';document.body.appendChild(a);if(\'loading\'!==document.readyState)c();else if(window.addEventListener)document.addEventListener(\'DOMContentLoaded\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\'loading\'!==document.readyState&amp;&amp;(document.onreadystatechange=e,c())}}}})();&lt;/script&gt;&lt;/body&gt;\r\n&lt;/html&gt;\r\n', service_info={}).error_details</failure></testcase><testcase classname="test_feature_flag_edge_cases.TestConcurrencyEdgeCases" name="test_concurrent_circuit_breaker_operations" time="0.016" /><testcase classname="test_feature_flag_edge_cases.TestConcurrencyEdgeCases" name="test_concurrent_cohort_assignment" time="0.009" /><testcase classname="test_feature_flag_edge_cases.TestConcurrencyEdgeCases" name="test_concurrent_cache_invalidation" time="0.013" /><testcase classname="test_feature_flag_edge_cases.TestResourceExhaustionEdgeCases" name="test_extreme_user_load_simulation" time="1.947"><failure message="AssertionError: Distribution incorrect: 15.001000000000001%&#10;assert 14.998999999999999 &lt; 2.0&#10; +  where 14.998999999999999 = abs((15.001000000000001 - 30.0))">lightrag_integration/tests/test_feature_flag_edge_cases.py:651: in test_extreme_user_load_simulation
    assert abs(lightrag_percentage - 30.0) &lt; 2.0, f"Distribution incorrect: {lightrag_percentage}%"
E   AssertionError: Distribution incorrect: 15.001000000000001%
E   assert 14.998999999999999 &lt; 2.0
E    +  where 14.998999999999999 = abs((15.001000000000001 - 30.0))</failure></testcase><testcase classname="test_feature_flag_edge_cases.TestResourceExhaustionEdgeCases" name="test_memory_usage_under_load" time="0.613" /><testcase classname="test_feature_flag_edge_cases.TestResourceExhaustionEdgeCases" name="test_service_degradation_under_load" time="6.003" /><testcase classname="test_feature_flag_edge_cases.TestConfigurationExtremeEdgeCases" name="test_contradictory_configuration_settings" time="0.005" /><testcase classname="test_feature_flag_edge_cases.TestConfigurationExtremeEdgeCases" name="test_invalid_json_routing_rules" time="0.005"><failure message="assert ('json' in &quot;expecting ',' delimiter: line 1 column 18 (char 17)&quot; or 'routing' in &quot;expecting ',' delimiter: line 1 column 18 (char 17)&quot;)&#10; +  where &quot;expecting ',' delimiter: line 1 column 18 (char 17)&quot; = &lt;built-in method lower of str object at 0x10c1fb6f0&gt;()&#10; +    where &lt;built-in method lower of str object at 0x10c1fb6f0&gt; = &quot;Expecting ',' delimiter: line 1 column 18 (char 17)&quot;.lower&#10; +      where &quot;Expecting ',' delimiter: line 1 column 18 (char 17)&quot; = str(JSONDecodeError(&quot;Expecting ',' delimiter: line 1 column 18 (char 17)&quot;))&#10; +  and   &quot;expecting ',' delimiter: line 1 column 18 (char 17)&quot; = &lt;built-in method lower of str object at 0x10c1fb6f0&gt;()&#10; +    where &lt;built-in method lower of str object at 0x10c1fb6f0&gt; = &quot;Expecting ',' delimiter: line 1 column 18 (char 17)&quot;.lower&#10; +      where &quot;Expecting ',' delimiter: line 1 column 18 (char 17)&quot; = str(JSONDecodeError(&quot;Expecting ',' delimiter: line 1 column 18 (char 17)&quot;))">lightrag_integration/tests/test_feature_flag_edge_cases.py:790: in test_invalid_json_routing_rules
    config = LightRAGConfig()
             ^^^^^^^^^^^^^^^^
&lt;string&gt;:47: in __init__
    ???
lightrag_integration/config.py:115: in &lt;lambda&gt;
    lightrag_routing_rules: Optional[Dict[str, Any]] = field(default_factory=lambda: json.loads(os.getenv("LIGHTRAG_ROUTING_RULES", "{}")) if os.getenv("LIGHTRAG_ROUTING_RULES") else None)
                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:346: in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:361: in raw_decode
    obj, end = self.scan_once(s, idx)
               ^^^^^^^^^^^^^^^^^^^^^^
E   json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 18 (char 17)

During handling of the above exception, another exception occurred:
lightrag_integration/tests/test_feature_flag_edge_cases.py:795: in test_invalid_json_routing_rules
    assert "json" in str(e).lower() or "routing" in str(e).lower()
E   assert ('json' in "expecting ',' delimiter: line 1 column 18 (char 17)" or 'routing' in "expecting ',' delimiter: line 1 column 18 (char 17)")
E    +  where "expecting ',' delimiter: line 1 column 18 (char 17)" = &lt;built-in method lower of str object at 0x10c1fb6f0&gt;()
E    +    where &lt;built-in method lower of str object at 0x10c1fb6f0&gt; = "Expecting ',' delimiter: line 1 column 18 (char 17)".lower
E    +      where "Expecting ',' delimiter: line 1 column 18 (char 17)" = str(JSONDecodeError("Expecting ',' delimiter: line 1 column 18 (char 17)"))
E    +  and   "expecting ',' delimiter: line 1 column 18 (char 17)" = &lt;built-in method lower of str object at 0x10c1fb6f0&gt;()
E    +    where &lt;built-in method lower of str object at 0x10c1fb6f0&gt; = "Expecting ',' delimiter: line 1 column 18 (char 17)".lower
E    +      where "Expecting ',' delimiter: line 1 column 18 (char 17)" = str(JSONDecodeError("Expecting ',' delimiter: line 1 column 18 (char 17)"))</failure></testcase><testcase classname="test_feature_flag_edge_cases.TestConfigurationExtremeEdgeCases" name="test_extreme_numeric_configuration_values" time="0.002" /><testcase classname="test_feature_flag_edge_cases.TestConfigurationExtremeEdgeCases" name="test_unicode_and_encoding_edge_cases" time="0.001" /><testcase classname="test_feature_flag_performance.TestHashingPerformance" name="test_hash_calculation_performance" time="0.015" /><testcase classname="test_feature_flag_performance.TestHashingPerformance" name="test_routing_decision_performance" time="0.110"><failure message="AssertionError: Unexpected distribution: 25.1%&#10;assert 40.0 &lt;= 25.1">lightrag_integration/tests/test_feature_flag_performance.py:290: in test_routing_decision_performance
    assert 40.0 &lt;= lightrag_percentage &lt;= 60.0, f"Unexpected distribution: {lightrag_percentage}%"
E   AssertionError: Unexpected distribution: 25.1%
E   assert 40.0 &lt;= 25.1</failure></testcase><testcase classname="test_feature_flag_performance.TestHashingPerformance" name="test_concurrent_routing_performance" time="0.081" /><testcase classname="test_feature_flag_performance.TestCachePerformance" name="test_routing_cache_performance" time="0.003" /><testcase classname="test_feature_flag_performance.TestCachePerformance" name="test_response_cache_performance" time="0.210" /><testcase classname="test_feature_flag_performance.TestCachePerformance" name="test_cache_memory_efficiency" time="0.075"><failure message="AssertionError: Cache size not bounded: 1001&#10;assert 1001 &lt;= 1000">lightrag_integration/tests/test_feature_flag_performance.py:511: in test_cache_memory_efficiency
    assert max_cache_size &lt;= 1000, f"Cache size not bounded: {max_cache_size}"
E   AssertionError: Cache size not bounded: 1001
E   assert 1001 &lt;= 1000</failure></testcase><testcase classname="test_feature_flag_performance.TestThroughputAndScalability" name="test_sustained_throughput" time="10.013" /><testcase classname="test_feature_flag_performance.TestThroughputAndScalability" name="test_scalability_with_user_count" time="0.135" /><testcase classname="test_feature_flag_performance.TestThroughputAndScalability" name="test_concurrent_service_throughput" time="0.488" /><testcase classname="test_feature_flag_performance.TestMemoryAndResourceUsage" name="test_memory_usage_under_load" time="0.715" /><testcase classname="test_feature_flag_performance.TestMemoryAndResourceUsage" name="test_cache_memory_efficiency_detailed" time="0.002"><failure message="RuntimeError: no running event loop">lightrag_integration/tests/test_feature_flag_performance.py:757: in test_cache_memory_efficiency_detailed
    service = IntegratedQueryService(config=config, perplexity_api_key="test")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
lightrag_integration/integration_wrapper.py:799: in __init__
    asyncio.create_task(self._start_background_tasks())
/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:407: in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: no running event loop</failure></testcase><testcase classname="test_feature_flag_performance.TestMemoryAndResourceUsage" name="test_resource_cleanup_efficiency" time="0.486" /><testcase classname="test_feature_flag_performance.TestPerformanceRegression" name="test_routing_decision_performance_baseline" time="0.094" /><testcase classname="test_feature_flag_performance.TestPerformanceRegression" name="test_memory_usage_baseline" time="0.339" /><testcase classname="test_feature_flag_performance.TestABTestingMetricsPerformance" name="test_ab_testing_metrics_collection_overhead" time="0.034" /></testsuite></testsuites>